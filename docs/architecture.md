# ğŸ—ï¸ Grape Vector Database - æŠ€æœ¯æ¶æ„è®¾è®¡

## ğŸ“– ç›®å½•

- [æ•´ä½“æ¶æ„æ¦‚è§ˆ](#æ•´ä½“æ¶æ„æ¦‚è§ˆ)
- [å†…åµŒæ¨¡å¼è®¾è®¡](#å†…åµŒæ¨¡å¼è®¾è®¡)
- [åˆ†å¸ƒå¼æ¶æ„è®¾è®¡](#åˆ†å¸ƒå¼æ¶æ„è®¾è®¡)
- [å­˜å‚¨å¼•æ“è®¾è®¡](#å­˜å‚¨å¼•æ“è®¾è®¡)
- [æŸ¥è¯¢å¼•æ“è®¾è®¡](#æŸ¥è¯¢å¼•æ“è®¾è®¡)
- [ç½‘ç»œåè®®è®¾è®¡](#ç½‘ç»œåè®®è®¾è®¡)
- [æ€§èƒ½ä¼˜åŒ–ç­–ç•¥](#æ€§èƒ½ä¼˜åŒ–ç­–ç•¥)

## ğŸŒŸ æ•´ä½“æ¶æ„æ¦‚è§ˆ

### æ ¸å¿ƒè®¾è®¡ç†å¿µ

**Grape Vector DB** é‡‡ç”¨ **åˆ†å±‚æ¨¡å—åŒ–** æ¶æ„ï¼Œæ”¯æŒ **å†…åµŒæ¨¡å¼** å’Œ **åˆ†å¸ƒå¼æ¨¡å¼** ä¸¤ç§éƒ¨ç½²æ–¹å¼ï¼š

```
                    â”Œâ”€ å†…åµŒæ¨¡å¼ (Embedded Mode)
Application Layer â”€â”€â”¤
                    â””â”€ æœåŠ¡æ¨¡å¼ (Service Mode)
                              â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              API Gateway Layer                   â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚ Qdrant å…¼å®¹å±‚â”‚ Native Grapeâ”‚ å†…åµŒæ¨¡å¼æ¥å£    â”‚ â”‚
â”‚  â”‚ (gRPC+REST) â”‚ API (é«˜æ€§èƒ½) â”‚ (åº“å½¢å¼é›†æˆ)     â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              Query Engine Layer                  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚ Dense Searchâ”‚ Sparse      â”‚ Hybrid Fusion   â”‚ â”‚
â”‚  â”‚ (HNSW)      â”‚ Search(BM25)â”‚ (RRF/Custom)    â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚             Storage Engine Layer                 â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚Vector Store â”‚ Metadata    â”‚ Index Store     â”‚ â”‚
â”‚  â”‚(Quantized)  â”‚ Store(JSON) â”‚ (HNSW+Inverted) â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚           Distributed Layer (å¯é€‰)               â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚ Cluster Mgr â”‚ Replication â”‚ Load Balancer   â”‚ â”‚
â”‚  â”‚ (Raft)      â”‚ (Consensus) â”‚ (Routing)       â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### æ¨¡å¼å¯¹æ¯”

| ç‰¹æ€§ | å†…åµŒæ¨¡å¼ | åˆ†å¸ƒå¼æ¨¡å¼ |
|------|----------|------------|
| **éƒ¨ç½²æ–¹å¼** | åº“å½¢å¼é›†æˆ | ç‹¬ç«‹æœåŠ¡é›†ç¾¤ |
| **ç½‘ç»œå¼€é”€** | æ—  | æœ‰ (gRPC/HTTP) |
| **æ•°æ®ä¸€è‡´æ€§** | å¼ºä¸€è‡´ | æœ€ç»ˆä¸€è‡´ |
| **æ‰©å±•æ€§** | å‚ç›´æ‰©å±• | æ°´å¹³æ‰©å±• |
| **é€‚ç”¨åœºæ™¯** | è¾¹ç¼˜è®¡ç®—ã€ç§»åŠ¨ç«¯ | å¤§è§„æ¨¡ä¼ä¸šåº”ç”¨ |

## ğŸ”§ å†…åµŒæ¨¡å¼è®¾è®¡

### æ ¸å¿ƒæ¶æ„

```rust
// å†…åµŒæ¨¡å¼æ ¸å¿ƒæ¥å£
pub struct EmbeddedVectorDB {
    engine: VectorEngine,
    storage: Box<dyn StorageEngine>,
    config: EmbeddedConfig,
    metrics: MetricsCollector,
}

impl EmbeddedVectorDB {
    // åŒæ­¥åˆå§‹åŒ– - å¿«é€Ÿå¯åŠ¨
    pub fn new(config: EmbeddedConfig) -> Result<Self> {
        let storage = Self::create_storage(&config)?;
        let engine = VectorEngine::new(storage.clone(), &config)?;
        Ok(Self { engine, storage, config, metrics: MetricsCollector::new() })
    }
    
    // å¼‚æ­¥æ“ä½œ - ä¿æŒé«˜æ€§èƒ½
    pub async fn upsert(&mut self, points: Vec<Point>) -> Result<()>;
    pub async fn search(&self, request: SearchRequest) -> Result<SearchResponse>;
    pub async fn delete(&mut self, filter: Filter) -> Result<usize>;
    
    // åŒæ­¥æ“ä½œ - ç®€åŒ–é›†æˆ
    pub fn search_sync(&self, request: SearchRequest) -> Result<SearchResponse>;
    pub fn stats(&self) -> DatabaseStats;
}
```

### å†…å­˜ç®¡ç†ç­–ç•¥

```rust
pub struct EmbeddedConfig {
    // å†…å­˜é¢„ç®—ç®¡ç†
    pub max_memory_mb: Option<usize>,
    pub vector_cache_size: usize,
    pub metadata_cache_size: usize,
    
    // å­˜å‚¨ç­–ç•¥
    pub storage_mode: StorageMode,
    pub compression_level: u8,
    pub enable_mmap: bool,
    
    // æ€§èƒ½è°ƒä¼˜
    pub thread_pool_size: Option<usize>,
    pub batch_size: usize,
    pub sync_interval: Duration,
}

pub enum StorageMode {
    Memory,           // çº¯å†…å­˜æ¨¡å¼
    MemoryWithDisk,   // å†…å­˜+ç£ç›˜å¤‡ä»½
    Disk,             // ç£ç›˜æ¨¡å¼(mmap)
    Hybrid,           // æ™ºèƒ½åˆ†å±‚å­˜å‚¨
}
```

### ç”Ÿå‘½å‘¨æœŸç®¡ç†

```rust
impl EmbeddedVectorDB {
    // ä¼˜é›…å…³é—­ - ç¡®ä¿æ•°æ®å®‰å…¨
    pub async fn shutdown(self) -> Result<()> {
        self.storage.flush().await?;
        self.storage.sync().await?;
        self.metrics.export_final_stats()?;
        Ok(())
    }
    
    // çƒ­å¤‡ä»½ - ä¸åœæœºå¤‡ä»½
    pub async fn backup(&self, path: &Path) -> Result<()> {
        self.storage.create_snapshot(path).await
    }
    
    // å¿«é€Ÿæ¢å¤ - æ•…éšœæ¢å¤
    pub async fn restore(path: &Path, config: EmbeddedConfig) -> Result<Self> {
        let storage = StorageEngine::restore_from_snapshot(path, &config).await?;
        let engine = VectorEngine::new(storage.clone(), &config)?;
        Ok(Self { engine, storage, config, metrics: MetricsCollector::new() })
    }
}
```

## ğŸŒ åˆ†å¸ƒå¼æ¶æ„è®¾è®¡

### é›†ç¾¤æ‹“æ‰‘

```
                    â”Œâ”€ Load Balancer â”€â”
                    â”‚                 â”‚
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚     Gateway        â”‚   â”‚    Gateway      â”‚
         â”‚    Node 1          â”‚   â”‚    Node 2       â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â”‚                 â”‚
     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
     â”‚              â”‚                 â”‚              â”‚
â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”       â”Œâ”€â”€â”€â”€â”€â–¼â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â–¼â”€â”€â”
â”‚Shard A â”‚    â”‚Shard B â”‚       â”‚Shard C â”‚     â”‚Shard D â”‚
â”‚Primary â”‚    â”‚Primary â”‚       â”‚Primary â”‚     â”‚Primary â”‚
â””â”€â”€â”€â”€â”¬â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”¬â”€â”€â”€â”˜       â””â”€â”€â”€â”€â”€â”¬â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”¬â”€â”€â”˜
     â”‚             â”‚                 â”‚              â”‚
â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”       â”Œâ”€â”€â”€â”€â”€â–¼â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â–¼â”€â”€â”
â”‚Shard A â”‚    â”‚Shard B â”‚       â”‚Shard C â”‚     â”‚Shard D â”‚
â”‚Replica â”‚    â”‚Replica â”‚       â”‚Replica â”‚     â”‚Replica â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜       â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Raft å…±è¯†å®ç°

```rust
pub struct RaftNode {
    node_id: NodeId,
    cluster: ClusterConfig,
    log: RaftLog,
    state_machine: VectorStateMachine,
    network: NetworkLayer,
}

pub enum RaftMessage {
    AppendEntries(AppendEntriesRequest),
    RequestVote(RequestVoteRequest),
    InstallSnapshot(InstallSnapshotRequest),
    // è‡ªå®šä¹‰å‘é‡æ“ä½œ
    VectorOperation(VectorOpRequest),
}

impl RaftNode {
    // å¤„ç†å®¢æˆ·ç«¯å†™è¯·æ±‚
    pub async fn handle_write(&mut self, op: VectorOperation) -> Result<Response> {
        if !self.is_leader() {
            return Err(Error::NotLeader(self.current_leader()));
        }
        
        // 1. å†™å…¥æ—¥å¿—
        let entry = LogEntry::new(op, self.current_term());
        let index = self.log.append(entry).await?;
        
        // 2. å¤åˆ¶åˆ°å¤šæ•°èŠ‚ç‚¹
        self.replicate_to_majority(index).await?;
        
        // 3. åº”ç”¨åˆ°çŠ¶æ€æœº
        let result = self.state_machine.apply(op).await?;
        
        Ok(Response::Success(result))
    }
    
    // å¤„ç†å®¢æˆ·ç«¯è¯»è¯·æ±‚
    pub async fn handle_read(&self, query: SearchRequest) -> Result<SearchResponse> {
        // å¼ºä¸€è‡´æ€§è¯» - ç¡®è®¤leadership
        self.confirm_leadership().await?;
        
        // ç›´æ¥ä»æœ¬åœ°çŠ¶æ€æœºè¯»å–
        self.state_machine.search(query).await
    }
}
```

### åˆ†ç‰‡ç­–ç•¥

```rust
pub struct ShardManager {
    shard_ring: ConsistentHashRing,
    shard_configs: HashMap<ShardId, ShardConfig>,
    rebalancer: ShardRebalancer,
}

pub enum ShardingStrategy {
    Hash(HashSharding),      // åŸºäºIDå“ˆå¸Œ
    Range(RangeSharding),    // åŸºäºå‘é‡èŒƒå›´
    Semantic(SemanticSharding), // åŸºäºè¯­ä¹‰ç›¸ä¼¼æ€§
    Custom(Box<dyn CustomSharding>), // è‡ªå®šä¹‰ç­–ç•¥
}

impl ShardManager {
    // æ™ºèƒ½åˆ†ç‰‡ - åŸºäºæ•°æ®ç‰¹å¾
    pub fn determine_shard(&self, point: &Point) -> ShardId {
        match &self.strategy {
            ShardingStrategy::Hash(h) => h.hash_point(point),
            ShardingStrategy::Semantic(s) => s.semantic_shard(point),
            // ... å…¶ä»–ç­–ç•¥
        }
    }
    
    // åŠ¨æ€é‡å¹³è¡¡
    pub async fn rebalance(&mut self) -> Result<()> {
        let imbalance = self.detect_imbalance().await?;
        if imbalance.severity > self.config.rebalance_threshold {
            self.rebalancer.execute_rebalance(imbalance).await?;
        }
        Ok(())
    }
}
```

## ğŸ’¾ å­˜å‚¨å¼•æ“è®¾è®¡ âœ… **Sledå¼•æ“å·²å‡çº§å®Œæˆ**

### Sled é«˜çº§å­˜å‚¨å¼•æ“

**Grape Vector DB** å·²å®Œæˆä»åŸºç¡€å­˜å‚¨åˆ°ä¼ä¸šçº§ **Sled é«˜çº§å­˜å‚¨å¼•æ“** çš„å‡çº§ï¼Œæä¾›ï¼š

- **ACID äº‹åŠ¡æ”¯æŒ** - å®Œæ•´çš„äº‹åŠ¡ä¸€è‡´æ€§ä¿è¯
- **å¤šæ ‘æ¶æ„** - ç±»ä¼¼åˆ—æ—çš„æ•°æ®ç»„ç»‡æ–¹å¼  
- **æ•°æ®å‹ç¼©** - 70% å‹ç¼©æ¯”ï¼ŒèŠ‚çœå­˜å‚¨ç©ºé—´
- **æ€§èƒ½ç›‘æ§** - å®æ—¶ç»Ÿè®¡å’Œæ€§èƒ½æŒ‡æ ‡
- **å¤‡ä»½æ¢å¤** - å®Œæ•´çš„æ•°æ®ä¿æŠ¤æœºåˆ¶

**å®é™…æ€§èƒ½è¡¨ç°**:
- å†™å…¥æ€§èƒ½: 13,240 QPS
- è¯»å–æ€§èƒ½: 42,018 QPS
- ç¼“å­˜å‘½ä¸­ç‡: 85%
- æ•°æ®å‹ç¼©æ¯”: 70%

### åˆ†å±‚å­˜å‚¨æ¶æ„

```rust
pub trait StorageEngine: Send + Sync {
    // å‘é‡å­˜å‚¨
    async fn store_vectors(&mut self, vectors: &[VectorRecord]) -> Result<()>;
    async fn load_vectors(&self, ids: &[PointId]) -> Result<Vec<VectorRecord>>;
    
    // å…ƒæ•°æ®å­˜å‚¨
    async fn store_metadata(&mut self, metadata: &[MetadataRecord]) -> Result<()>;
    async fn query_metadata(&self, filter: &Filter) -> Result<Vec<PointId>>;
    
    // ç´¢å¼•å­˜å‚¨
    async fn store_index(&mut self, index: &Index) -> Result<()>;
    async fn load_index(&self) -> Result<Index>;
    
    // äº‹åŠ¡æ”¯æŒ
    async fn begin_transaction(&mut self) -> Result<TransactionId>;
    async fn commit_transaction(&mut self, txn_id: TransactionId) -> Result<()>;
    async fn rollback_transaction(&mut self, txn_id: TransactionId) -> Result<()>;
}

// æ··åˆå­˜å‚¨å®ç°
pub struct HybridStorageEngine {
    // çƒ­æ•°æ® - å†…å­˜å­˜å‚¨
    hot_vectors: Arc<RwLock<HashMap<PointId, VectorRecord>>>,
    hot_metadata: Arc<RwLock<HashMap<PointId, MetadataRecord>>>,
    
    // æ¸©æ•°æ® - SSDå­˜å‚¨
            warm_storage: SledStorage,
    
    // å†·æ•°æ® - å¯¹è±¡å­˜å‚¨
    cold_storage: ObjectStorage,
    
    // æ•°æ®åˆ†çº§ç­–ç•¥
    tiering_policy: TieringPolicy,
}
```

### å‘é‡é‡åŒ–å­˜å‚¨

```rust
pub struct QuantizedVectorStorage {
    // åŸå§‹å‘é‡(å¯é€‰ä¿å­˜)
    original_vectors: Option<Box<dyn VectorStorage>>,
    
    // é‡åŒ–å‘é‡
    quantized_vectors: Box<dyn QuantizedStorage>,
    
    // é‡åŒ–å‚æ•°
    quantization_config: QuantizationConfig,
}

pub enum QuantizationType {
    Binary {
        threshold: f32,
        rescore_multiplier: usize,
    },
    Scalar {
        bits_per_component: u8,
        min_values: Vec<f32>,
        max_values: Vec<f32>,
    },
    Product {
        num_codebooks: usize,
        codebook_size: usize,
        centroids: Vec<Vec<f32>>,
    },
}

impl QuantizedVectorStorage {
    // é«˜æ€§èƒ½é‡åŒ–æœç´¢
    pub async fn search_quantized(
        &self,
        query: &[f32],
        k: usize,
    ) -> Result<Vec<ScoredPoint>> {
        // 1. é‡åŒ–æŸ¥è¯¢å‘é‡
        let quantized_query = self.quantize_vector(query)?;
        
        // 2. å¿«é€Ÿç²—æ’
        let candidates = self.quantized_vectors
            .search(&quantized_query, k * self.config.oversample_factor)
            .await?;
        
        // 3. ç²¾ç¡®é‡æ’åº(å¯é€‰)
        if let Some(original) = &self.original_vectors {
            self.rescore_with_original(candidates, query, k).await
        } else {
            Ok(candidates)
        }
    }
}
```

## ğŸ” æŸ¥è¯¢å¼•æ“è®¾è®¡

### æ··åˆæœç´¢æ¶æ„

```rust
pub struct HybridQueryEngine {
    dense_engine: DenseSearchEngine,
    sparse_engine: SparseSearchEngine,
    fusion_engine: FusionEngine,
    filter_engine: FilterEngine,
}

pub struct SearchRequest {
    // å¯†é›†å‘é‡æŸ¥è¯¢
    pub dense_vector: Option<Vec<f32>>,
    
    // ç¨€ç–å‘é‡æŸ¥è¯¢
    pub sparse_vector: Option<SparseVector>,
    
    // æ–‡æœ¬æŸ¥è¯¢(è‡ªåŠ¨è½¬æ¢ä¸ºç¨€ç–å‘é‡)
    pub text_query: Option<String>,
    
    // è¿‡æ»¤æ¡ä»¶
    pub filter: Option<Filter>,
    
    // èåˆå‚æ•°
    pub fusion_config: Option<FusionConfig>,
    
    // åŸºæœ¬å‚æ•°
    pub limit: usize,
    pub offset: usize,
}

impl HybridQueryEngine {
    pub async fn search(&self, request: SearchRequest) -> Result<SearchResponse> {
        let mut results = Vec::new();
        
        // 1. å¹¶è¡Œæ‰§è¡Œä¸åŒç±»å‹æœç´¢
        let (dense_fut, sparse_fut) = tokio::join!(
            self.execute_dense_search(&request),
            self.execute_sparse_search(&request)
        );
        
        // 2. æ”¶é›†ç»“æœ
        if let Ok(dense_results) = dense_fut {
            results.push((SearchType::Dense, dense_results));
        }
        if let Ok(sparse_results) = sparse_fut {
            results.push((SearchType::Sparse, sparse_results));
        }
        
        // 3. èåˆå¤šè·¯ç»“æœ
        let fused_results = self.fusion_engine.fuse(results, &request.fusion_config)?;
        
        // 4. åº”ç”¨è¿‡æ»¤å™¨
        let filtered_results = self.filter_engine.apply_filter(
            fused_results,
            &request.filter
        ).await?;
        
        Ok(SearchResponse {
            points: filtered_results,
            total: filtered_results.len(),
        })
    }
}
```

### æ™ºèƒ½ç¼“å­˜ç³»ç»Ÿ

```rust
pub struct CacheManager {
    // æŸ¥è¯¢ç»“æœç¼“å­˜
    query_cache: Arc<Mutex<LruCache<QueryHash, SearchResponse>>>,
    
    // å‘é‡ç¼“å­˜
    vector_cache: Arc<Mutex<LruCache<PointId, VectorRecord>>>,
    
    // ç´¢å¼•ç¼“å­˜
    index_cache: Arc<Mutex<LruCache<IndexId, Box<dyn Index>>>>,
    
    // ç¼“å­˜ç­–ç•¥
    cache_policy: CachePolicy,
}

pub enum CachePolicy {
    LRU { max_size: usize },
    LFU { max_size: usize },
    TTL { ttl: Duration },
    Adaptive { learn_rate: f32 },
}

impl CacheManager {
    // æ™ºèƒ½é¢„å–
    pub async fn prefetch_related(&self, query: &SearchRequest) -> Result<()> {
        // åŸºäºæŸ¥è¯¢å†å²é¢„æµ‹ç›¸å…³æŸ¥è¯¢
        let related_queries = self.predict_related_queries(query).await?;
        
        // å¼‚æ­¥é¢„å–
        let prefetch_tasks: Vec<_> = related_queries
            .into_iter()
            .map(|q| self.execute_prefetch(q))
            .collect();
        
        // å¹¶å‘æ‰§è¡Œé¢„å–ï¼Œä¸é˜»å¡ä¸»æŸ¥è¯¢
        tokio::spawn(async move {
            futures::future::join_all(prefetch_tasks).await;
        });
        
        Ok(())
    }
}
```

## ğŸŒ ç½‘ç»œåè®®è®¾è®¡

### gRPC æœåŠ¡æ¥å£

```protobuf
syntax = "proto3";

service VectorService {
    // åŸºç¡€æ“ä½œ
    rpc Upsert(UpsertRequest) returns (UpsertResponse);
    rpc Search(SearchRequest) returns (SearchResponse);
    rpc Delete(DeleteRequest) returns (DeleteResponse);
    
    // æ‰¹é‡æ“ä½œ
    rpc BatchUpsert(stream UpsertRequest) returns (UpsertResponse);
    rpc BatchSearch(stream SearchRequest) returns (stream SearchResponse);
    
    // é›†ç¾¤æ“ä½œ
    rpc GetClusterInfo(Empty) returns (ClusterInfo);
    rpc HealthCheck(Empty) returns (HealthResponse);
    
    // æµå¼æ“ä½œ
    rpc Subscribe(SubscribeRequest) returns (stream ChangeEvent);
}

message Point {
    string id = 1;
    repeated float vector = 2;
    google.protobuf.Struct payload = 3;
}

message SearchRequest {
    repeated float vector = 1;
    uint32 limit = 2;
    google.protobuf.Struct filter = 3;
    SearchParams params = 4;
}
```

### å†…éƒ¨é€šä¿¡åè®®

```rust
pub enum InternalMessage {
    // é›†ç¾¤åè°ƒ
    JoinCluster { node_info: NodeInfo },
    LeaveCluster { node_id: NodeId },
    
    // æ•°æ®åŒæ­¥
    SyncRequest { shard_id: ShardId, from_version: u64 },
    SyncResponse { data: Vec<SyncRecord> },
    
    // è´Ÿè½½å‡è¡¡
    LoadReport { metrics: NodeMetrics },
    RouteRequest { query: SearchRequest },
    
    // æ•…éšœå¤„ç†
    FailureDetected { failed_node: NodeId },
    RecoveryComplete { recovered_node: NodeId },
}

pub struct MessageRouter {
    node_id: NodeId,
    network: NetworkLayer,
    handlers: HashMap<MessageType, Box<dyn MessageHandler>>,
}

impl MessageRouter {
    // é«˜æ•ˆæ¶ˆæ¯è·¯ç”±
    pub async fn route_message(&self, msg: InternalMessage) -> Result<()> {
        let msg_type = msg.message_type();
        let handler = self.handlers.get(&msg_type)
            .ok_or(Error::UnknownMessageType(msg_type))?;
        
        // å¼‚æ­¥å¤„ç†ï¼Œé¿å…é˜»å¡
        let handler = handler.clone();
        tokio::spawn(async move {
            if let Err(e) = handler.handle(msg).await {
                tracing::error!("Message handling failed: {}", e);
            }
        });
        
        Ok(())
    }
}
```

## âš¡ æ€§èƒ½ä¼˜åŒ–ç­–ç•¥

### SIMD å‘é‡è¿ç®—

```rust
use std::arch::x86_64::*;

pub struct SIMDVectorOps;

impl SIMDVectorOps {
    // AVX2 ä¼˜åŒ–çš„ä½™å¼¦ç›¸ä¼¼åº¦è®¡ç®—
    #[target_feature(enable = "avx2")]
    pub unsafe fn cosine_similarity_avx2(a: &[f32], b: &[f32]) -> f32 {
        assert_eq!(a.len(), b.len());
        assert_eq!(a.len() % 8, 0);
        
        let mut dot_product = _mm256_setzero_ps();
        let mut norm_a = _mm256_setzero_ps();
        let mut norm_b = _mm256_setzero_ps();
        
        for i in (0..a.len()).step_by(8) {
            let va = _mm256_loadu_ps(a.as_ptr().add(i));
            let vb = _mm256_loadu_ps(b.as_ptr().add(i));
            
            dot_product = _mm256_fmadd_ps(va, vb, dot_product);
            norm_a = _mm256_fmadd_ps(va, va, norm_a);
            norm_b = _mm256_fmadd_ps(vb, vb, norm_b);
        }
        
        // æ°´å¹³æ±‚å’Œ
        let dot = Self::horizontal_sum_avx2(dot_product);
        let norm_a = Self::horizontal_sum_avx2(norm_a).sqrt();
        let norm_b = Self::horizontal_sum_avx2(norm_b).sqrt();
        
        dot / (norm_a * norm_b)
    }
}
```

### é›¶æ‹·è´æ•°æ®ä¼ è¾“

```rust
pub struct ZeroCopyBuffer {
    mmap: memmap2::Mmap,
    layout: BufferLayout,
}

impl ZeroCopyBuffer {
    // é›¶æ‹·è´å‘é‡è®¿é—®
    pub fn get_vector(&self, index: usize) -> &[f32] {
        let offset = self.layout.vector_offset(index);
        let size = self.layout.vector_size;
        
        unsafe {
            std::slice::from_raw_parts(
                self.mmap.as_ptr().add(offset) as *const f32,
                size
            )
        }
    }
    
    // é›¶æ‹·è´æ‰¹é‡å‘é‡è®¿é—®
    pub fn get_vectors_batch(&self, indices: &[usize]) -> Vec<&[f32]> {
        indices.iter()
            .map(|&i| self.get_vector(i))
            .collect()
    }
}
```

### æ™ºèƒ½é¢„å–ç­–ç•¥

```rust
pub struct PrefetchManager {
    access_patterns: LruCache<QueryPattern, AccessPattern>,
    prefetch_queue: Arc<Mutex<VecDeque<PrefetchTask>>>,
    background_executor: tokio::task::JoinHandle<()>,
}

impl PrefetchManager {
    // åŸºäºæœºå™¨å­¦ä¹ çš„é¢„å–å†³ç­–
    pub async fn should_prefetch(&self, query: &SearchRequest) -> bool {
        let pattern = self.extract_pattern(query);
        
        if let Some(access_pattern) = self.access_patterns.get(&pattern) {
            // åŸºäºå†å²å‘½ä¸­ç‡å†³ç­–
            access_pattern.hit_rate > 0.7 && access_pattern.access_frequency > 10
        } else {
            // æ–°æ¨¡å¼ï¼Œä¿å®ˆé¢„å–
            false
        }
    }
    
    // å¼‚æ­¥åå°é¢„å–
    async fn execute_prefetch(&self, task: PrefetchTask) -> Result<()> {
        match task {
            PrefetchTask::Vectors(ids) => {
                self.storage.warm_cache_vectors(&ids).await?;
            }
            PrefetchTask::Index(index_id) => {
                self.storage.warm_cache_index(index_id).await?;
            }
            PrefetchTask::Metadata(filter) => {
                self.storage.warm_cache_metadata(&filter).await?;
            }
        }
        Ok(())
    }
}
```

---

**æ–‡æ¡£ç‰ˆæœ¬**: v1.0  
**æœ€åæ›´æ–°**: 2024å¹´  
**ç»´æŠ¤è€…**: Grape Vector DB æ¶æ„å›¢é˜Ÿ 