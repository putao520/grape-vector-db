use anyhow::Result;
use serde::{Deserialize, Serialize};
use std::collections::HashMap;
use std::path::Path;
use std::sync::OnceLock;

static SYSTEM_CONFIG: OnceLock<SystemConfig> = OnceLock::new();

/// ç³»ç»Ÿé…ç½®ç»“æ„
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct SystemConfig {
    pub vector_search: VectorSearchConfig,
    pub api_limits: ApiLimitsConfig,
    pub content_analysis: ContentAnalysisConfig,
    pub similarity_detection: SimilarityDetectionConfig,
    pub performance: PerformanceConfig,
    pub ai_integration: AiIntegrationConfig,
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct VectorSearchConfig {
    pub cache_limit: usize,
    pub similarity_threshold: f32,
    pub search_timeout_ms: u64,
    pub max_results_per_query: usize,
    pub embedding_cache_ttl_hours: u64,
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct ApiLimitsConfig {
    pub github_per_page: usize,
    pub batch_processing_size: usize,
    pub concurrent_requests: usize,
    pub retry_attempts: u32,
    pub backoff_multiplier: u32,
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct ContentAnalysisConfig {
    pub min_content_length: usize,
    pub max_document_length: usize,
    pub chunk_size: usize,
    pub chunk_overlap: usize,
    pub quality_weights: HashMap<String, f64>,
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct SimilarityDetectionConfig {
    pub text_similarity_weight: f32,
    pub structure_similarity_weight: f32,
    pub keyword_similarity_weight: f32,
    pub complexity_similarity_weight: f32,
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct PerformanceConfig {
    pub cache_cleanup_interval_hours: u64,
    pub vector_dimension: usize,
    pub index_rebuild_threshold: usize,
    pub memory_limit_mb: usize,
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct AiIntegrationConfig {
    pub default_model: String,
    pub fallback_to_statistical: bool,
    pub enable_real_ai_analysis: bool,
    pub api_timeout_seconds: u64,
}

/// æ··åˆæœç´¢æƒé‡é…ç½®
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct HybridWeights {
    /// å¯†é›†å‘é‡æƒé‡
    pub dense_weight: f32,
    /// ç¨€ç–å‘é‡æƒé‡  
    pub sparse_weight: f32,
    /// æ–‡æœ¬æœç´¢æƒé‡
    pub text_weight: f32,
}

impl Default for HybridWeights {
    fn default() -> Self {
        Self {
            dense_weight: 0.7,
            sparse_weight: 0.2,
            text_weight: 0.1,
        }
    }
}

/// BM25 ç®—æ³•é…ç½®
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct BM25Config {
    /// k1 å‚æ•°ï¼Œæ§åˆ¶è¯é¢‘é¥±å’Œåº¦
    pub k1: f32,
    /// b å‚æ•°ï¼Œæ§åˆ¶æ–‡æ¡£é•¿åº¦å½’ä¸€åŒ–
    pub b: f32,
    /// æ˜¯å¦å¯ç”¨ç¨€ç–å‘é‡ç´¢å¼•
    pub enabled: bool,
}

impl Default for BM25Config {
    fn default() -> Self {
        Self {
            k1: 1.2,
            b: 0.75,
            enabled: true,
        }
    }
}

/// æ··åˆæœç´¢é…ç½®
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct HybridSearchConfig {
    /// èåˆç­–ç•¥
    pub fusion_strategy: crate::types::FusionStrategy,
    /// å„æƒé‡é…ç½®
    pub weights: HybridWeights,
    /// BM25 é…ç½®
    pub bm25: BM25Config,
    /// æ˜¯å¦å¯ç”¨æ··åˆæœç´¢
    pub enabled: bool,
    /// æœ€å¤§å€™é€‰ç»“æœæ•°ï¼ˆç”¨äºèåˆå‰çš„æœç´¢ï¼‰
    pub max_candidates: usize,
}

impl Default for HybridSearchConfig {
    fn default() -> Self {
        Self {
            fusion_strategy: crate::types::FusionStrategy::default(),
            weights: HybridWeights::default(),
            bm25: BM25Config::default(),
            enabled: true,
            max_candidates: 100,
        }
    }
}

/// ç¨€ç–å‘é‡é…ç½®
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct SparseVectorConfig {
    /// æ˜¯å¦å¯ç”¨ç¨€ç–å‘é‡
    pub enabled: bool,
    /// æœ€å¤§è¯æ±‡è¡¨å¤§å°
    pub max_vocabulary_size: usize,
    /// åœç”¨è¯æ–‡ä»¶è·¯å¾„ï¼ˆå¯é€‰ï¼‰
    pub stopwords_file: Option<String>,
    /// æ˜¯å¦è‡ªåŠ¨æ›´æ–°è¯æ±‡è¡¨
    pub auto_update_vocabulary: bool,
    /// è¯æ±‡è¡¨æ›´æ–°é—´éš”ï¼ˆæ–‡æ¡£æ•°ï¼‰
    pub vocabulary_update_interval: usize,
}

impl Default for SparseVectorConfig {
    fn default() -> Self {
        Self {
            enabled: true,
            max_vocabulary_size: 100000,
            stopwords_file: None,
            auto_update_vocabulary: true,
            vocabulary_update_interval: 1000,
        }
    }
}

/// å‘é‡æ•°æ®åº“é…ç½®
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct VectorDbConfig {
    /// å‘é‡ç»´åº¦
    pub vector_dimension: usize,
    
    /// HNSW é…ç½®
    pub hnsw: HnswConfig,
    
    /// åµŒå…¥æä¾›è€…é…ç½®
    pub embedding: EmbeddingConfig,
    
    /// ç¼“å­˜é…ç½®
    pub cache: CacheConfig,
    
    /// æŒä¹…åŒ–é…ç½®
    pub persistence: PersistenceConfig,
    
    /// æŸ¥è¯¢é…ç½®
    pub query: QueryConfig,

    /// æ··åˆæœç´¢é…ç½®
    pub hybrid_search: HybridSearchConfig,
    /// ç¨€ç–å‘é‡é…ç½®
    pub sparse_vector: SparseVectorConfig,
}

/// HNSW ç´¢å¼•é…ç½®
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct HnswConfig {
    /// æ„å»ºæ—¶çš„è¿æ¥æ•°
    pub m: usize,
    
    /// æ„å»ºæ—¶çš„å€™é€‰æ•°
    pub ef_construction: usize,
    
    /// æœç´¢æ—¶çš„å€™é€‰æ•°
    pub ef_search: usize,
    
    /// æœ€å¤§å±‚æ•°
    pub max_layers: usize,
}

/// åµŒå…¥é…ç½®
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct EmbeddingConfig {
    /// æä¾›è€…ç±»å‹ (openai, azure, nvidia, huggingface, local, mock)
    pub provider: String,
    
    /// API ç«¯ç‚¹URL (æ”¯æŒè‡ªå®šä¹‰ç«¯ç‚¹)
    pub endpoint: Option<String>,
    
    /// API å¯†é’¥æˆ–token
    pub api_key: Option<String>,
    
    /// æ¨¡å‹åç§°
    pub model: String,
    
    /// API ç‰ˆæœ¬ï¼ˆç”¨äºAzureç­‰æœåŠ¡ï¼‰
    pub api_version: Option<String>,
    
    /// è‡ªå®šä¹‰è¯·æ±‚å¤´
    pub headers: HashMap<String, String>,
    
    /// æ‰¹é‡å¤§å°
    pub batch_size: usize,
    
    /// è¯·æ±‚è¶…æ—¶ï¼ˆç§’ï¼‰
    pub timeout_seconds: u64,
    
    /// é‡è¯•æ¬¡æ•°
    pub retry_attempts: u32,
    
    /// å‘é‡ç»´åº¦ï¼ˆå¦‚æœå·²çŸ¥ï¼‰
    pub dimension: Option<usize>,
}

/// ç¼“å­˜é…ç½®
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct CacheConfig {
    /// åµŒå…¥ç¼“å­˜å¤§å°
    pub embedding_cache_size: usize,
    
    /// æŸ¥è¯¢ç»“æœç¼“å­˜å¤§å°
    pub query_cache_size: usize,
    
    /// ç¼“å­˜TTLï¼ˆç§’ï¼‰
    pub cache_ttl_seconds: u64,
}

/// æŒä¹…åŒ–é…ç½®
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct PersistenceConfig {
    /// æ•°æ®ç›®å½•
    pub data_dir: String,
    
    /// è‡ªåŠ¨ä¿å­˜é—´éš”ï¼ˆç§’ï¼‰
    pub auto_save_interval_seconds: u64,
    
    /// å‹ç¼©é€‰é¡¹
    pub compression: bool,
    
    /// å¤‡ä»½é€‰é¡¹
    pub backup: bool,
}

/// æŸ¥è¯¢é…ç½®
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct QueryConfig {
    /// é»˜è®¤æœç´¢é™åˆ¶
    pub default_limit: usize,
    
    /// æœ€å¤§æœç´¢é™åˆ¶
    pub max_limit: usize,
    
    /// æ··åˆæœç´¢æƒé‡
    pub hybrid_weights: HybridWeights,
    
    /// ç›¸ä¼¼åº¦é˜ˆå€¼
    pub similarity_threshold: f32,
}

impl Default for SystemConfig {
    fn default() -> Self {
        let mut quality_weights = HashMap::new();
        quality_weights.insert("word_count".to_string(), 0.15);
        quality_weights.insert("sentence_count".to_string(), 0.10);
        quality_weights.insert("avg_word_length".to_string(), 0.10);
        quality_weights.insert("code_block_count".to_string(), 0.20);
        quality_weights.insert("link_count".to_string(), 0.15);
        quality_weights.insert("heading_count".to_string(), 0.15);
        quality_weights.insert("complexity_score".to_string(), 0.15);

        Self {
            vector_search: VectorSearchConfig {
                cache_limit: 1000,
                similarity_threshold: 0.85,
                search_timeout_ms: 1000,
                max_results_per_query: 100,
                embedding_cache_ttl_hours: 24,
            },
            api_limits: ApiLimitsConfig {
                github_per_page: 100,
                batch_processing_size: 50,
                concurrent_requests: 10,
                retry_attempts: 3,
                backoff_multiplier: 2,
            },
            content_analysis: ContentAnalysisConfig {
                min_content_length: 100,
                max_document_length: 10000,
                chunk_size: 1000,
                chunk_overlap: 100,
                quality_weights,
            },
            similarity_detection: SimilarityDetectionConfig {
                text_similarity_weight: 0.4,
                structure_similarity_weight: 0.25,
                keyword_similarity_weight: 0.25,
                complexity_similarity_weight: 0.1,
            },
            performance: PerformanceConfig {
                cache_cleanup_interval_hours: 12,
                vector_dimension: 1536,
                index_rebuild_threshold: 10000,
                memory_limit_mb: 512,
            },
            ai_integration: AiIntegrationConfig {
                default_model: "nvidia/nv-embedqa-mistral-7b-v2".to_string(),
                fallback_to_statistical: true,
                enable_real_ai_analysis: true,
                api_timeout_seconds: 30,
            },
        }
    }
}

impl SystemConfig {
    /// åŠ è½½é…ç½®æ–‡ä»¶
    pub fn load() -> &'static SystemConfig {
        SYSTEM_CONFIG.get_or_init(|| {
            // å°è¯•ä»å¤šä¸ªä½ç½®åŠ è½½é…ç½®æ–‡ä»¶
            let config_paths = vec![
                "config/system_config.toml",
                "system_config.toml",
                "./config/system_config.toml",
            ];
            
            for path in config_paths {
                if Path::new(path).exists() {
                    match Self::load_from_file(path) {
                        Ok(config) => {
                            tracing::info!("âœ… å·²åŠ è½½é…ç½®æ–‡ä»¶: {}", path);
                            return config;
                        }
                        Err(e) => {
                            tracing::warn!("âš ï¸ æ— æ³•åŠ è½½é…ç½®æ–‡ä»¶ {}: {}", path, e);
                        }
                    }
                }
            }
            
            tracing::info!("ğŸ“ ä½¿ç”¨é»˜è®¤é…ç½®");
            Self::default()
        })
    }
    
    /// ä»æ–‡ä»¶åŠ è½½é…ç½®
    fn load_from_file(path: &str) -> Result<SystemConfig> {
        let content = std::fs::read_to_string(path)?;
        let config: SystemConfig = toml::from_str(&content)?;
        Ok(config)
    }
    
    /// è·å–å…¨å±€é…ç½®å®ä¾‹
    pub fn get() -> &'static SystemConfig {
        SYSTEM_CONFIG.get().unwrap_or_else(|| {
            // å¦‚æœé…ç½®è¿˜æ²¡æœ‰åˆå§‹åŒ–ï¼Œå…ˆåˆå§‹åŒ–å®ƒ
            Self::load()
        })
    }
    
    /// ä¿å­˜é…ç½®åˆ°æ–‡ä»¶
    pub fn save_to_file(&self, path: &str) -> Result<()> {
        let content = toml::to_string_pretty(self)?;
        std::fs::write(path, content)?;
        tracing::info!("ğŸ’¾ é…ç½®å·²ä¿å­˜åˆ°: {}", path);
        Ok(())
    }
}

impl Default for VectorDbConfig {
    fn default() -> Self {
        Self {
            vector_dimension: 768,
            hnsw: HnswConfig::default(),
            embedding: EmbeddingConfig::default(),
            cache: CacheConfig::default(),
            persistence: PersistenceConfig::default(),
            query: QueryConfig::default(),
            hybrid_search: HybridSearchConfig::default(),
            sparse_vector: SparseVectorConfig::default(),
        }
    }
}

impl Default for HnswConfig {
    fn default() -> Self {
        Self {
            m: 16,
            ef_construction: 200,
            ef_search: 100,
            max_layers: 16,
        }
    }
}

impl Default for EmbeddingConfig {
    fn default() -> Self {
        Self {
            provider: "mock".to_string(), // é»˜è®¤ä½¿ç”¨mockä»¥ä¾¿äºæµ‹è¯•
            endpoint: None,
            api_key: None,
            model: "text-embedding-3-small".to_string(), // OpenAIé»˜è®¤æ¨¡å‹
            api_version: None,
            headers: HashMap::new(),
            batch_size: 32,
            timeout_seconds: 30,
            retry_attempts: 3,
            dimension: Some(1536), // OpenAI text-embedding-3-small çš„ç»´åº¦
        }
    }
}

impl Default for CacheConfig {
    fn default() -> Self {
        Self {
            embedding_cache_size: 10000,
            query_cache_size: 1000,
            cache_ttl_seconds: 86400, // 24å°æ—¶
        }
    }
}

impl Default for PersistenceConfig {
    fn default() -> Self {
        Self {
            data_dir: "./vector_data".to_string(),
            auto_save_interval_seconds: 300, // 5åˆ†é’Ÿ
            compression: true,
            backup: false,
        }
    }
}

impl Default for QueryConfig {
    fn default() -> Self {
        Self {
            default_limit: 10,
            max_limit: 100,
            hybrid_weights: HybridWeights::default(),
            similarity_threshold: 0.5,
        }
    }
} 