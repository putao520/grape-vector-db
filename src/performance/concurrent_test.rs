use crate::{VectorDatabase, VectorDbConfig, Document, concurrent::*};
use std::sync::Arc;
use std::time::Instant;
#[cfg(test)]
use tempfile::TempDir;

/// å¹¶å‘æ€§èƒ½æµ‹è¯•å¥—ä»¶
#[cfg(test)]
pub struct ConcurrentPerformanceTest {
    pub db: Arc<VectorDatabase>,
    pub counters: Arc<AtomicCounters>,
    pub cache: Arc<ConcurrentHashMap<String, Vec<String>>>,
}

#[cfg(test)]
impl ConcurrentPerformanceTest {
    /// åˆ›å»ºæ–°çš„æ€§èƒ½æµ‹è¯•å®ä¾‹
    pub async fn new() -> Result<Self, Box<dyn std::error::Error>> {
        let temp_dir = TempDir::new()?;
        let config = VectorDbConfig::default();
        let db = Arc::new(VectorDatabase::new(temp_dir.path().to_path_buf(), config).await?);
        
        Ok(Self {
            db,
            counters: Arc::new(AtomicCounters::new()),
            cache: Arc::new(ConcurrentHashMap::new()),
        })
    }

    /// å¹¶å‘æ’å…¥æ€§èƒ½æµ‹è¯•
    pub async fn test_concurrent_insertions(&self, batch_count: usize, batch_size: usize) -> Result<f64, Box<dyn std::error::Error>> {
        println!("ğŸš€ æµ‹è¯•å¹¶å‘æ’å…¥æ€§èƒ½ï¼š{} æ‰¹æ¬¡ï¼Œæ¯æ‰¹ {} ä¸ªæ–‡æ¡£", batch_count, batch_size);
        
        let start_time = Instant::now();
        let mut handles = Vec::new();
        
        for batch_id in 0..batch_count {
            let db = self.db.clone();
            let counters = self.counters.clone();
            
            let handle = tokio::spawn(async move {
                let mut documents = Vec::new();
                
                for doc_id in 0..batch_size {
                    let id = format!("batch_{}_doc_{}", batch_id, doc_id);
                    let doc = Document {
                        id: id.clone(),
                        title: Some(format!("å¹¶å‘æµ‹è¯•æ–‡æ¡£ {}", id)),
                        content: format!("è¿™æ˜¯æ‰¹æ¬¡ {} ä¸­çš„ç¬¬ {} ä¸ªæµ‹è¯•æ–‡æ¡£ï¼Œç”¨äºå¹¶å‘æ€§èƒ½æµ‹è¯•", batch_id, doc_id),
                        language: Some("zh".to_string()),
                        version: Some("1".to_string()),
                        doc_type: Some("performance_test".to_string()),
                        package_name: Some("concurrent_test".to_string()),
                        vector: Some(vec![0.1 * (batch_id as f32 + doc_id as f32); 128]),
                        metadata: std::collections::HashMap::new(),
                        created_at: chrono::Utc::now(),
                        updated_at: chrono::Utc::now(),
                    };
                    documents.push(doc);
                }
                
                counters.increment_operations();
                let result = db.batch_add_documents(documents).await;
                
                match result {
                    Ok(_) => counters.increment_successful_operations(),
                    Err(_) => counters.increment_failed_operations(),
                }
                
                result
            });
            
            handles.push(handle);
        }
        
        // ç­‰å¾…æ‰€æœ‰æ‰¹æ¬¡å®Œæˆ
        let mut total_docs = 0;
        for handle in handles {
            match handle.await? {
                Ok(doc_ids) => total_docs += doc_ids.len(),
                Err(e) => eprintln!("æ‰¹æ¬¡æ’å…¥å¤±è´¥: {}", e),
            }
        }
        
        let elapsed = start_time.elapsed();
        let docs_per_second = total_docs as f64 / elapsed.as_secs_f64();
        
        println!("âœ… å¹¶å‘æ’å…¥å®Œæˆ:");
        println!("   æ€»æ–‡æ¡£æ•°: {}", total_docs);
        println!("   è€—æ—¶: {:?}", elapsed);
        println!("   æ€§èƒ½: {:.2} æ–‡æ¡£/ç§’", docs_per_second);
        println!("   æˆåŠŸç‡: {:.1}%", self.counters.success_rate() * 100.0);
        
        Ok(docs_per_second)
    }

    /// å¹¶å‘æœç´¢æ€§èƒ½æµ‹è¯•
    pub async fn test_concurrent_searches(&self, concurrent_searches: usize, searches_per_thread: usize) -> Result<f64, Box<dyn std::error::Error>> {
        println!("ğŸ” æµ‹è¯•å¹¶å‘æœç´¢æ€§èƒ½ï¼š{} ä¸ªå¹¶å‘çº¿ç¨‹ï¼Œæ¯çº¿ç¨‹ {} æ¬¡æœç´¢", concurrent_searches, searches_per_thread);
        
        let queries = vec![
            "å¹¶å‘æµ‹è¯•", "æ€§èƒ½ä¼˜åŒ–", "å‘é‡æ•°æ®åº“", "æ–‡æ¡£æœç´¢", 
            "å¤šçº¿ç¨‹", "å¼‚æ­¥å¤„ç†", "é«˜æ€§èƒ½", "æ‰¹é‡æ“ä½œ",
            "ç¼“å­˜ä¼˜åŒ–", "å†…å­˜ç®¡ç†", "æ•°æ®ç»“æ„", "ç®—æ³•ä¼˜åŒ–",
        ];
        
        let start_time = Instant::now();
        let mut handles = Vec::new();
        
        for thread_id in 0..concurrent_searches {
            let db = self.db.clone();
            let counters = self.counters.clone();
            let cache = self.cache.clone();
            let queries = queries.clone();
            
            let handle = tokio::spawn(async move {
                let mut successful_searches = 0;
                
                for search_id in 0..searches_per_thread {
                    let query = &queries[search_id % queries.len()];
                    let cache_key = format!("{}_{}", thread_id, search_id);
                    
                    counters.increment_search_operations();
                    
                    // æ£€æŸ¥ç¼“å­˜
                    if let Some(_cached) = cache.get(&cache_key) {
                        counters.increment_cache_hits();
                        successful_searches += 1;
                        continue;
                    }
                    
                    // æ‰§è¡Œæœç´¢
                    match db.text_search(query, 10).await {
                        Ok(results) => {
                            // ç¼“å­˜ç»“æœ
                            let result_ids: Vec<String> = results.iter()
                                .map(|r| r.document.id.clone())
                                .collect();
                            cache.insert(cache_key, result_ids);
                            
                            counters.increment_cache_misses();
                            counters.increment_successful_operations();
                            successful_searches += 1;
                        },
                        Err(_) => {
                            counters.increment_failed_operations();
                        }
                    }
                }
                
                successful_searches
            });
            
            handles.push(handle);
        }
        
        // ç­‰å¾…æ‰€æœ‰æœç´¢å®Œæˆ
        let mut total_searches = 0;
        for handle in handles {
            total_searches += handle.await?;
        }
        
        let elapsed = start_time.elapsed();
        let searches_per_second = total_searches as f64 / elapsed.as_secs_f64();
        
        println!("âœ… å¹¶å‘æœç´¢å®Œæˆ:");
        println!("   æ€»æœç´¢æ¬¡æ•°: {}", total_searches);
        println!("   è€—æ—¶: {:?}", elapsed);
        println!("   æ€§èƒ½: {:.2} æœç´¢/ç§’", searches_per_second);
        println!("   ç¼“å­˜å‘½ä¸­ç‡: {:.1}%", self.counters.cache_hit_rate() * 100.0);
        println!("   æˆåŠŸç‡: {:.1}%", self.counters.success_rate() * 100.0);
        
        Ok(searches_per_second)
    }

    /// æ··åˆå·¥ä½œè´Ÿè½½æµ‹è¯•
    pub async fn test_mixed_workload(&self, duration_secs: u64) -> Result<(), Box<dyn std::error::Error>> {
        println!("âš¡ æµ‹è¯•æ··åˆå·¥ä½œè´Ÿè½½ï¼šæŒç»­ {} ç§’", duration_secs);
        
        let end_time = Instant::now() + std::time::Duration::from_secs(duration_secs);
        let mut handles = Vec::new();
        
        // å¯åŠ¨æ’å…¥ä»»åŠ¡
        let db_insert = self.db.clone();
        let counters_insert = self.counters.clone();
        let insert_handle = tokio::spawn(async move {
            let mut doc_counter = 0;
            while Instant::now() < end_time {
                let doc = Document {
                    id: format!("mixed_doc_{}", doc_counter),
                    title: Some(format!("æ··åˆè´Ÿè½½æ–‡æ¡£ {}", doc_counter)),
                    content: format!("è¿™æ˜¯æ··åˆè´Ÿè½½æµ‹è¯•ä¸­çš„ç¬¬ {} ä¸ªæ–‡æ¡£", doc_counter),
                    language: Some("zh".to_string()),
                    version: Some("1".to_string()),
                    doc_type: Some("mixed_test".to_string()),
                    package_name: Some("mixed_workload".to_string()),
                    vector: Some(vec![0.01 * doc_counter as f32; 128]),
                    metadata: std::collections::HashMap::new(),
                    created_at: chrono::Utc::now(),
                    updated_at: chrono::Utc::now(),
                };
                
                if db_insert.add_document(doc).await.is_ok() {
                    counters_insert.increment_successful_operations();
                } else {
                    counters_insert.increment_failed_operations();
                }
                
                doc_counter += 1;
                tokio::time::sleep(std::time::Duration::from_millis(10)).await;
            }
        });
        handles.push(insert_handle);
        
        // å¯åŠ¨æœç´¢ä»»åŠ¡
        let db_search = self.db.clone();
        let counters_search = self.counters.clone();
        let search_handle = tokio::spawn(async move {
            let queries = vec!["æ··åˆ", "è´Ÿè½½", "æµ‹è¯•", "æ–‡æ¡£", "æ€§èƒ½"];
            let mut query_counter = 0;
            
            while Instant::now() < end_time {
                let query = &queries[query_counter % queries.len()];
                
                if db_search.text_search(query, 5).await.is_ok() {
                    counters_search.increment_successful_operations();
                } else {
                    counters_search.increment_failed_operations();
                }
                
                counters_search.increment_search_operations();
                query_counter += 1;
                tokio::time::sleep(std::time::Duration::from_millis(50)).await;
            }
        });
        handles.push(search_handle);
        
        // ç­‰å¾…æ‰€æœ‰ä»»åŠ¡å®Œæˆ
        for handle in handles {
            handle.await?;
        }
        
        println!("âœ… æ··åˆå·¥ä½œè´Ÿè½½æµ‹è¯•å®Œæˆ:");
        println!("   æ€»æ“ä½œæ•°: {}", self.counters.get_operations());
        println!("   æˆåŠŸç‡: {:.1}%", self.counters.success_rate() * 100.0);
        println!("   æœç´¢æ“ä½œæ•°: {}", self.counters.search_operations.load(std::sync::atomic::Ordering::Relaxed));
        
        Ok(())
    }

    /// è¿è¡Œå®Œæ•´çš„æ€§èƒ½æµ‹è¯•å¥—ä»¶
    pub async fn run_full_suite(&self) -> Result<(), Box<dyn std::error::Error>> {
        println!("ğŸ å¼€å§‹å®Œæ•´å¹¶å‘æ€§èƒ½æµ‹è¯•å¥—ä»¶");
        println!("=====================================");
        
        // é‡ç½®è®¡æ•°å™¨
        self.counters.reset();
        
        // 1. å¹¶å‘æ’å…¥æµ‹è¯•
        let insert_perf = self.test_concurrent_insertions(5, 20).await?;
        println!();
        
        // 2. å¹¶å‘æœç´¢æµ‹è¯•
        let search_perf = self.test_concurrent_searches(10, 20).await?;
        println!();
        
        // 3. æ··åˆå·¥ä½œè´Ÿè½½æµ‹è¯•
        self.test_mixed_workload(10).await?;
        println!();
        
        // æ€»ç»“
        println!("ğŸ“Š æ€§èƒ½æµ‹è¯•æ€»ç»“:");
        println!("================");
        println!("   æ’å…¥æ€§èƒ½: {:.2} æ–‡æ¡£/ç§’", insert_perf);
        println!("   æœç´¢æ€§èƒ½: {:.2} æœç´¢/ç§’", search_perf);
        println!("   ç¼“å­˜å‘½ä¸­ç‡: {:.1}%", self.counters.cache_hit_rate() * 100.0);
        println!("   æ€»ä½“æˆåŠŸç‡: {:.1}%", self.counters.success_rate() * 100.0);
        
        // æ€§èƒ½ç­‰çº§è¯„ä¼°
        if insert_perf > 1000.0 && search_perf > 500.0 {
            println!("   ğŸ† æ€§èƒ½ç­‰çº§: ä¼˜ç§€");
        } else if insert_perf > 500.0 && search_perf > 200.0 {
            println!("   ğŸ¥ˆ æ€§èƒ½ç­‰çº§: è‰¯å¥½");
        } else if insert_perf > 100.0 && search_perf > 50.0 {
            println!("   ğŸ¥‰ æ€§èƒ½ç­‰çº§: ä¸€èˆ¬");
        } else {
            println!("   âš ï¸  æ€§èƒ½ç­‰çº§: éœ€è¦ä¼˜åŒ–");
        }
        
        Ok(())
    }
}

#[cfg(test)]
mod tests {
    use super::*;

    #[tokio::test]
    async fn test_concurrent_performance_suite() {
        let test_suite = ConcurrentPerformanceTest::new().await.unwrap();
        
        // è¿è¡Œä¸€ä¸ªç®€åŒ–çš„æµ‹è¯•ç‰ˆæœ¬
        let insert_perf = test_suite.test_concurrent_insertions(2, 10).await.unwrap();
        assert!(insert_perf > 0.0, "æ’å…¥æ€§èƒ½åº”è¯¥å¤§äº0");
        
        let search_perf = test_suite.test_concurrent_searches(3, 5).await.unwrap();
        assert!(search_perf > 0.0, "æœç´¢æ€§èƒ½åº”è¯¥å¤§äº0");
        
        println!("å¹¶å‘æ€§èƒ½æµ‹è¯•é€šè¿‡ï¼šæ’å…¥ {:.2} doc/s, æœç´¢ {:.2} search/s", insert_perf, search_perf);
    }
}