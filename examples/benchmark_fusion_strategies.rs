//! èåˆç­–ç•¥åŸºå‡†æµ‹è¯•ç¤ºä¾‹
//!
//! æ­¤ç¤ºä¾‹æ¼”ç¤ºå¦‚ä½•ä½¿ç”¨ä¸åŒçš„èåˆç­–ç•¥è¿›è¡Œæ€§èƒ½åŸºå‡†æµ‹è¯•

use grape_vector_db::{
    hybrid::{FusionContext, FusionModel, QueryType, StatisticalFusionModel, TimeContext},
    types::Document,
    VectorDatabase, VectorDbConfig,
};
use std::collections::HashMap;
use std::path::PathBuf;

#[tokio::main]
async fn main() -> Result<(), Box<dyn std::error::Error>> {
    println!("ğŸš€ Grape Vector DB - èåˆç­–ç•¥åŸºå‡†æµ‹è¯•æ¼”ç¤º");

    // 1. åˆå§‹åŒ–æ•°æ®åº“
    let config = VectorDbConfig::default();
    let data_dir = PathBuf::from("./temp_demo_db");
    let db = VectorDatabase::new(data_dir, config).await?;

    // 2. å‡†å¤‡æµ‹è¯•æ•°æ®
    let test_documents = generate_test_documents();
    println!("ğŸ“š ç”Ÿæˆäº† {} ä¸ªæµ‹è¯•æ–‡æ¡£", test_documents.len());

    // æ’å…¥æµ‹è¯•æ–‡æ¡£
    for doc in &test_documents {
        db.add_document(doc.clone()).await?;
    }

    println!("âœ… æ–‡æ¡£æ’å…¥å®Œæˆ");

    // éªŒè¯æœç´¢åŠŸèƒ½
    println!("ğŸ” éªŒè¯æœç´¢åŠŸèƒ½...");
    match db.semantic_search("æµ‹è¯•æŸ¥è¯¢", 5).await {
        Ok(results) => println!("âœ… è¯­ä¹‰æœç´¢åŠŸèƒ½æ­£å¸¸ï¼Œæ‰¾åˆ° {} ä¸ªç»“æœ", results.len()),
        Err(e) => {
            println!("âŒ æœç´¢éªŒè¯å¤±è´¥: {}", e);
            return Err(e.into());
        }
    }

    // 3. æµ‹è¯•ä¸åŒçš„èåˆç­–ç•¥
    println!("\nğŸ¯ å¼€å§‹èåˆç­–ç•¥æ€§èƒ½æµ‹è¯•...\n");

    let strategies = vec![
        ("RRF_æ¨¡æ‹Ÿ", 0.5, 0.3, 0.2),
        ("çº¿æ€§_å¹³è¡¡", 0.5, 0.3, 0.2),
        ("çº¿æ€§_å¯†é›†åé‡", 0.7, 0.2, 0.1),
        ("çº¿æ€§_ç¨€ç–åé‡", 0.3, 0.6, 0.1),
        ("æ ‡å‡†åŒ–èåˆ", 0.6, 0.3, 0.1),
        ("å­¦ä¹ å¼æ¨¡æ‹Ÿ", 0.55, 0.35, 0.1),
        ("è‡ªé€‚åº”æ¨¡æ‹Ÿ", 0.65, 0.25, 0.1),
    ];

    let mut all_results = Vec::new();

    for (name, dense_weight, sparse_weight, text_weight) in strategies {
        println!("ğŸ“Š æµ‹è¯•ç­–ç•¥: {}", name);

        // ä½¿ç”¨ç›¸åŒçš„æ•°æ®åº“ä½†ä¸åŒçš„æƒé‡é…ç½®è¿è¡Œæµ‹è¯•
        let result = run_simple_benchmark_with_weights(
            &db,
            name,
            &test_documents,
            dense_weight,
            sparse_weight,
            text_weight,
        )
        .await?;
        all_results.push(result);

        println!("   âœ“ å®Œæˆ");
    }

    // 5. åˆ†æç»“æœ
    println!("\nğŸ“ˆ åŸºå‡†æµ‹è¯•ç»“æœåˆ†æ:\n");

    print_benchmark_results(&all_results);

    // 6. æ¼”ç¤ºå­¦ä¹ å¼èåˆæ¨¡å‹
    println!("\nğŸ§  å­¦ä¹ å¼èåˆæ¨¡å‹æ¼”ç¤º:");
    demonstrate_learning_model()?;

    println!("\nğŸ‰ åŸºå‡†æµ‹è¯•æ¼”ç¤ºå®Œæˆ!");
    Ok(())
}

/// ç”Ÿæˆæµ‹è¯•æ–‡æ¡£
fn generate_test_documents() -> Vec<Document> {
    let now = chrono::Utc::now();
    vec![
        Document {
            id: "doc1".to_string(),
            title: Some("å‘é‡æ•°æ®åº“ä»‹ç»".to_string()),
            content: "å‘é‡æ•°æ®åº“æ˜¯ä¸€ç§ä¸“é—¨ç”¨äºå­˜å‚¨å’Œæ£€ç´¢é«˜ç»´å‘é‡æ•°æ®çš„æ•°æ®åº“ç³»ç»Ÿã€‚å®ƒæ”¯æŒè¯­ä¹‰æœç´¢å’Œç›¸ä¼¼æ€§æŸ¥è¯¢ã€‚".to_string(),
            language: Some("zh".to_string()),
            package_name: Some("demo".to_string()),
            version: Some("1.0".to_string()),
            doc_type: Some("article".to_string()),
            vector: None,
            metadata: HashMap::new(),
            created_at: now,
            updated_at: now,
        },
        Document {
            id: "doc2".to_string(),
            title: Some("æœºå™¨å­¦ä¹ åŸºç¡€".to_string()),
            content: "æœºå™¨å­¦ä¹ æ˜¯äººå·¥æ™ºèƒ½çš„ä¸€ä¸ªé‡è¦åˆ†æ”¯ï¼Œé€šè¿‡ç®—æ³•è®©è®¡ç®—æœºè‡ªåŠ¨å­¦ä¹ æ•°æ®ä¸­çš„æ¨¡å¼ã€‚".to_string(),
            language: Some("zh".to_string()),
            package_name: Some("demo".to_string()),
            version: Some("1.0".to_string()),
            doc_type: Some("article".to_string()),
            vector: None,
            metadata: HashMap::new(),
            created_at: now,
            updated_at: now,
        },
        Document {
            id: "doc3".to_string(),
            title: Some("æ·±åº¦å­¦ä¹ æŠ€æœ¯".to_string()),
            content: "æ·±åº¦å­¦ä¹ ä½¿ç”¨ç¥ç»ç½‘ç»œæ¨¡å‹å¤„ç†å¤æ‚çš„æ•°æ®æ¨¡å¼ï¼Œåœ¨å›¾åƒè¯†åˆ«å’Œè‡ªç„¶è¯­è¨€å¤„ç†æ–¹é¢è¡¨ç°ä¼˜å¼‚ã€‚".to_string(),
            language: Some("zh".to_string()),
            package_name: Some("demo".to_string()),
            version: Some("1.0".to_string()),
            doc_type: Some("article".to_string()),
            vector: None,
            metadata: HashMap::new(),
            created_at: now,
            updated_at: now,
        },
        Document {
            id: "doc4".to_string(),
            title: Some("æœç´¢å¼•æ“ä¼˜åŒ–".to_string()),
            content: "æœç´¢å¼•æ“ä¼˜åŒ–(SEO)æ˜¯æé«˜ç½‘ç«™åœ¨æœç´¢å¼•æ“ç»“æœé¡µé¢æ’åçš„æŠ€æœ¯å’Œç­–ç•¥ã€‚".to_string(),
            language: Some("zh".to_string()),
            package_name: Some("demo".to_string()),
            version: Some("1.0".to_string()),
            doc_type: Some("article".to_string()),
            vector: None,
            metadata: HashMap::new(),
            created_at: now,
            updated_at: now,
        },
        Document {
            id: "doc5".to_string(),
            title: Some("åˆ†å¸ƒå¼ç³»ç»Ÿ".to_string()),
            content: "åˆ†å¸ƒå¼ç³»ç»Ÿæ˜¯ç”±å¤šä¸ªç‹¬ç«‹è®¡ç®—æœºç»„æˆçš„ç³»ç»Ÿï¼Œå®ƒä»¬é€šè¿‡ç½‘ç»œé€šä¿¡åä½œå®Œæˆä»»åŠ¡ã€‚".to_string(),
            language: Some("zh".to_string()),
            package_name: Some("demo".to_string()),
            version: Some("1.0".to_string()),
            doc_type: Some("article".to_string()),
            vector: None,
            metadata: HashMap::new(),
            created_at: now,
            updated_at: now,
        },
        Document {
            id: "doc6".to_string(),
            title: Some("æ•°æ®åº“è®¾è®¡".to_string()),
            content: "è‰¯å¥½çš„æ•°æ®åº“è®¾è®¡æ˜¯æ„å»ºé«˜æ•ˆåº”ç”¨ç¨‹åºçš„åŸºç¡€ï¼Œéœ€è¦è€ƒè™‘æ€§èƒ½ã€æ‰©å±•æ€§å’Œæ•°æ®ä¸€è‡´æ€§ã€‚".to_string(),
            language: Some("zh".to_string()),
            package_name: Some("demo".to_string()),
            version: Some("1.0".to_string()),
            doc_type: Some("article".to_string()),
            vector: None,
            metadata: HashMap::new(),
            created_at: now,
            updated_at: now,
        },
        Document {
            id: "doc7".to_string(),
            title: Some("APIå¼€å‘æœ€ä½³å®è·µ".to_string()),
            content: "RESTful APIè®¾è®¡åº”è¯¥éµå¾ªç»Ÿä¸€çš„æ¥å£è§„èŒƒï¼Œæä¾›æ¸…æ™°çš„é”™è¯¯å¤„ç†å’Œå®Œæ•´çš„æ–‡æ¡£ã€‚".to_string(),
            language: Some("zh".to_string()),
            package_name: Some("demo".to_string()),
            version: Some("1.0".to_string()),
            doc_type: Some("article".to_string()),
            vector: None,
            metadata: HashMap::new(),
            created_at: now,
            updated_at: now,
        },
        Document {
            id: "doc8".to_string(),
            title: Some("äº‘è®¡ç®—å¹³å°".to_string()),
            content: "äº‘è®¡ç®—æä¾›æŒ‰éœ€çš„è®¡ç®—èµ„æºï¼ŒåŒ…æ‹¬åŸºç¡€è®¾æ–½å³æœåŠ¡(IaaS)ã€å¹³å°å³æœåŠ¡(PaaS)å’Œè½¯ä»¶å³æœåŠ¡(SaaS)ã€‚".to_string(),
            language: Some("zh".to_string()),
            package_name: Some("demo".to_string()),
            version: Some("1.0".to_string()),
            doc_type: Some("article".to_string()),
            vector: None,
            metadata: HashMap::new(),
            created_at: now,
            updated_at: now,
        },
    ]
}

/// ç®€åŒ–çš„åŸºå‡†æµ‹è¯•ç»“æ„
#[derive(Debug)]
struct SimpleBenchmarkResult {
    strategy_name: String,
    avg_latency_ms: f64,
    throughput_qps: f64,
    success_rate: f64,
    sample_precision: f64,
}

/// è¿è¡Œç®€åŒ–çš„åŸºå‡†æµ‹è¯•ï¼ˆå¸¦æƒé‡é…ç½®ï¼‰
async fn run_simple_benchmark_with_weights(
    db: &VectorDatabase,
    strategy_name: &str,
    _test_docs: &[Document],
    _dense_weight: f32,
    _sparse_weight: f32,
    _text_weight: f32,
) -> Result<SimpleBenchmarkResult, Box<dyn std::error::Error>> {
    let test_queries = [
        "å‘é‡æ•°æ®åº“æœç´¢",
        "æœºå™¨å­¦ä¹ ç®—æ³•",
        "æ·±åº¦å­¦ä¹ ç¥ç»ç½‘ç»œ",
        "æœç´¢å¼•æ“æŠ€æœ¯",
        "åˆ†å¸ƒå¼ç³»ç»Ÿæ¶æ„",
    ];

    let start_time = std::time::Instant::now();
    let mut latencies = Vec::new();
    let mut successful_queries = 0;
    let mut total_precision = 0.0;

    for query in test_queries.iter() {
        let query_start = std::time::Instant::now();

        // æ‰§è¡Œè¯­ä¹‰æœç´¢
        match db.semantic_search(query, 5).await {
            Ok(results) => {
                let latency = query_start.elapsed().as_millis() as f64;
                latencies.push(latency);
                successful_queries += 1;

                // ç®€å•çš„ç²¾ç¡®åº¦è®¡ç®—ï¼ˆåŸºäºç»“æœæ•°é‡ï¼‰
                let precision = if results.is_empty() {
                    0.0
                } else {
                    (results.len() as f64 / 5.0).min(1.0)
                };
                total_precision += precision;
            }
            Err(_) => {
                latencies.push(5000.0); // é”™è¯¯æ—¶è®°å½•é«˜å»¶è¿Ÿ
            }
        }
    }

    let total_time = start_time.elapsed();
    let avg_latency = latencies.iter().sum::<f64>() / latencies.len() as f64;
    let throughput = successful_queries as f64 / total_time.as_secs_f64();
    let success_rate = successful_queries as f64 / test_queries.len() as f64;
    let avg_precision = total_precision / test_queries.len() as f64;

    Ok(SimpleBenchmarkResult {
        strategy_name: strategy_name.to_string(),
        avg_latency_ms: avg_latency,
        throughput_qps: throughput,
        success_rate,
        sample_precision: avg_precision,
    })
}

/// æ‰“å°åŸºå‡†æµ‹è¯•ç»“æœ
fn print_benchmark_results(results: &[SimpleBenchmarkResult]) {
    println!("â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”");
    println!("â”‚ ç­–ç•¥            â”‚ å¹³å‡å»¶è¿Ÿ(ms) â”‚ ååé‡(QPS)  â”‚ æˆåŠŸç‡      â”‚ æ ·æœ¬ç²¾ç¡®åº¦   â”‚");
    println!("â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤");

    for result in results {
        println!(
            "â”‚ {:15} â”‚ {:12.2} â”‚ {:12.2} â”‚ {:11.1}% â”‚ {:12.3} â”‚",
            result.strategy_name,
            result.avg_latency_ms,
            result.throughput_qps,
            result.success_rate * 100.0,
            result.sample_precision
        );
    }

    println!("â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜");

    // æ‰¾å‡ºæœ€ä½³æ€§èƒ½æŒ‡æ ‡
    if let Some(best_latency) = results
        .iter()
        .min_by(|a, b| a.avg_latency_ms.partial_cmp(&b.avg_latency_ms).unwrap())
    {
        println!(
            "\nğŸ† æœ€ä½å»¶è¿Ÿ: {} ({:.2}ms)",
            best_latency.strategy_name, best_latency.avg_latency_ms
        );
    }

    if let Some(best_throughput) = results
        .iter()
        .max_by(|a, b| a.throughput_qps.partial_cmp(&b.throughput_qps).unwrap())
    {
        println!(
            "ğŸ† æœ€é«˜ååé‡: {} ({:.2} QPS)",
            best_throughput.strategy_name, best_throughput.throughput_qps
        );
    }

    if let Some(best_precision) = results
        .iter()
        .max_by(|a, b| a.sample_precision.partial_cmp(&b.sample_precision).unwrap())
    {
        println!(
            "ğŸ† æœ€é«˜ç²¾ç¡®åº¦: {} ({:.3})",
            best_precision.strategy_name, best_precision.sample_precision
        );
    }
}

/// æ¼”ç¤ºå­¦ä¹ å¼èåˆæ¨¡å‹
fn demonstrate_learning_model() -> Result<(), Box<dyn std::error::Error>> {
    println!("  åˆ›å»ºç»Ÿè®¡å­¦ä¹ æ¨¡å‹...");

    let mut model = StatisticalFusionModel::new(0.01);

    // æ¨¡æ‹Ÿä¸€äº›è®­ç»ƒæ•°æ®
    use grape_vector_db::types::QueryMetrics;

    let training_data = vec![
        QueryMetrics {
            query_id: "test_query_1".to_string(),
            query_text: "ç¤ºä¾‹æŸ¥è¯¢".to_string(),
            timestamp: 1_640_995_200_000, // 2022-01-01 00:00:00 UTC
            duration_ms: 150.0,
            result_count: 10,
            clicked_results: vec!["doc1".to_string(), "doc3".to_string()],
            user_satisfaction: Some(4),
            fusion_strategy: "learned".to_string(),
        },
        QueryMetrics {
            query_id: "test_query_2".to_string(),
            query_text: "å¦ä¸€ä¸ªæŸ¥è¯¢".to_string(),
            timestamp: 1_641_081_600_000, // 2022-01-02 00:00:00 UTC
            duration_ms: 120.0,
            result_count: 8,
            clicked_results: vec!["doc2".to_string()],
            user_satisfaction: Some(5),
            fusion_strategy: "learned".to_string(),
        },
    ];

    // è®­ç»ƒæ¨¡å‹
    for metrics in training_data {
        model.update_model(&metrics)?;
    }

    // æµ‹è¯•é¢„æµ‹
    let test_context = FusionContext {
        query_type: QueryType::Semantic,
        query_length: 15,
        historical_ctr: 0.75,
        time_context: TimeContext::WorkingHours,
    };

    let predicted_weights = model.predict_weights("æ·±åº¦å­¦ä¹ æŠ€æœ¯", &test_context);

    println!("  ğŸ“Š é¢„æµ‹çš„æœ€ä½³æƒé‡:");
    println!("    - å¯†é›†å‘é‡æƒé‡: {:.3}", predicted_weights.dense_weight);
    println!("    - ç¨€ç–å‘é‡æƒé‡: {:.3}", predicted_weights.sparse_weight);
    println!("    - æ–‡æœ¬æœç´¢æƒé‡: {:.3}", predicted_weights.text_weight);

    Ok(())
}
