/// æ··æ²Œå·¥ç¨‹ç»¼åˆæµ‹è¯•
///
/// å…¨é¢æµ‹è¯•ç³»ç»Ÿåœ¨å„ç§å¼‚å¸¸æ¡ä»¶ä¸‹çš„è¡Œä¸ºï¼ŒåŒ…æ‹¬ï¼š
/// - å¤§è§„æ¨¡æ•…éšœæ³¨å…¥
/// - ç½‘ç»œåˆ†åŒºå’Œæ¢å¤
/// - æ•°æ®ä¸€è‡´æ€§éªŒè¯
/// - æ€§èƒ½é™çº§åˆ†æ
/// - è‡ªåŠ¨æ¢å¤èƒ½åŠ›
mod test_framework;

use anyhow::Result;
use std::collections::HashMap;
use std::time::Duration;
use chrono;

use grape_vector_db::types::*;
use test_framework::*;

/// ç³»ç»Ÿçº§æ··æ²Œå·¥ç¨‹æµ‹è¯•
#[cfg(test)]
mod system_chaos_tests {
    use super::*;
    use crate::test_framework::{ChaosExperimentBuilder, NetworkChaos, WorkloadConfig};

    #[tokio::test]
    async fn test_disaster_recovery() {
        let cluster = TestCluster::new(ClusterType::SixNode).await;
        cluster.start_all_nodes().await.unwrap();

        println!("ğŸ”¥ ç¾éš¾æ¢å¤æµ‹è¯•å¼€å§‹...");

        // ç¬¬ä¸€é˜¶æ®µï¼šå»ºç«‹åŸºçº¿æ•°æ®
        println!("é˜¶æ®µ1: å»ºç«‹åŸºçº¿æ•°æ®");
        let critical_docs = generate_critical_documents(100);
        for doc in &critical_docs {
            cluster.insert_document(doc.clone()).await.unwrap();
        }

        let baseline_stats = cluster.get_cluster_stats().await;
        println!("åŸºçº¿çŠ¶æ€: {:?}", baseline_stats);

        // ç¬¬äºŒé˜¶æ®µï¼šæ¨¡æ‹Ÿç¾éš¾æ€§æ•…éšœ
        println!("é˜¶æ®µ2: æ¨¡æ‹Ÿç¾éš¾æ€§æ•…éšœ");

        // åŒæ—¶åœæ­¢4ä¸ªèŠ‚ç‚¹ï¼ˆåªå‰©2ä¸ªèŠ‚ç‚¹ï¼‰
        for i in 2..6 {
            cluster.stop_node(&format!("node_{}", i)).await.unwrap();
        }

        tokio::time::sleep(Duration::from_millis(500)).await;

        let disaster_stats = cluster.get_cluster_stats().await;
        println!("ç¾éš¾åçŠ¶æ€: {:?}", disaster_stats);

        // éªŒè¯ç³»ç»Ÿè¿›å…¥é™çº§æ¨¡å¼
        assert_eq!(disaster_stats.active_nodes, 2, "åº”è¯¥åªæœ‰2ä¸ªèŠ‚ç‚¹å­˜æ´»");

        // ç¬¬ä¸‰é˜¶æ®µï¼šæµ‹è¯•æ•°æ®è®¿é—®èƒ½åŠ›
        println!("é˜¶æ®µ3: æµ‹è¯•é™çº§æ¨¡å¼ä¸‹çš„æ•°æ®è®¿é—®");
        let mut accessible_count = 0;
        let mut total_attempts = 0;

        for doc in &critical_docs[..20] {
            total_attempts += 1;
            if cluster.get_document(&doc.id).await.is_ok() {
                accessible_count += 1;
            }
        }

        let accessibility_ratio = accessible_count as f64 / total_attempts as f64;
        println!("é™çº§æ¨¡å¼æ•°æ®å¯è®¿é—®æ€§: {:.1}%", accessibility_ratio * 100.0);

        // ç¬¬å››é˜¶æ®µï¼šç¾éš¾æ¢å¤
        println!("é˜¶æ®µ4: æ‰§è¡Œç¾éš¾æ¢å¤");

        // é€æ­¥é‡å¯èŠ‚ç‚¹
        for i in 2..6 {
            println!("æ¢å¤èŠ‚ç‚¹ node_{}", i);
            cluster.restart_node(&format!("node_{}", i)).await.unwrap();
            tokio::time::sleep(Duration::from_millis(300)).await;

            let recovery_stats = cluster.get_cluster_stats().await;
            println!("  å½“å‰æ´»è·ƒèŠ‚ç‚¹: {}", recovery_stats.active_nodes);
        }

        // ç­‰å¾…é›†ç¾¤å®Œå…¨æ¢å¤
        tokio::time::sleep(Duration::from_secs(1)).await;

        // ç¬¬äº”é˜¶æ®µï¼šéªŒè¯å®Œå…¨æ¢å¤
        println!("é˜¶æ®µ5: éªŒè¯å®Œå…¨æ¢å¤");

        let final_stats = cluster.get_cluster_stats().await;
        assert_eq!(final_stats.active_nodes, 6, "æ‰€æœ‰èŠ‚ç‚¹åº”è¯¥æ¢å¤");
        assert!(final_stats.is_healthy, "é›†ç¾¤åº”è¯¥å®Œå…¨å¥åº·");

        // éªŒè¯æ•°æ®å®Œæ•´æ€§
        let mut recovered_count = 0;
        for doc in &critical_docs {
            if cluster.get_document(&doc.id).await.is_ok() {
                recovered_count += 1;
            }
        }

        let recovery_ratio = recovered_count as f64 / critical_docs.len() as f64;
        println!("æ•°æ®æ¢å¤ç‡: {:.1}%", recovery_ratio * 100.0);

        // ç¾éš¾æ¢å¤æ–­è¨€
        assert!(
            accessibility_ratio >= 0.3,
            "é™çº§æ¨¡å¼ä¸‹è‡³å°‘30%æ•°æ®åº”è¯¥å¯è®¿é—®"
        );
        assert!(recovery_ratio >= 0.95, "ç¾éš¾æ¢å¤åè‡³å°‘95%æ•°æ®åº”è¯¥æ¢å¤");

        println!("âœ… ç¾éš¾æ¢å¤æµ‹è¯•é€šè¿‡");
    }

    #[tokio::test]
    async fn test_byzantine_failures() {
        let cluster = TestCluster::new(ClusterType::SixNode).await;
        cluster.start_all_nodes().await.unwrap();

        println!("ğŸ­ æ‹œå åº­æ•…éšœæµ‹è¯•å¼€å§‹...");

        // æ’å…¥æµ‹è¯•æ•°æ®
        let test_docs = generate_test_documents(60);
        for doc in &test_docs {
            cluster.insert_document(doc.clone()).await.unwrap();
        }

        // æ¨¡æ‹Ÿæ‹œå åº­æ•…éšœï¼šèŠ‚ç‚¹è¡Œä¸ºå¼‚å¸¸ä½†æœªå®Œå…¨å¤±æ•ˆ
        println!("æ¨¡æ‹Ÿæ‹œå åº­æ•…éšœ...");

        // æ¨¡æ‹Ÿä¸åŒç±»å‹çš„æ‹œå åº­æ•…éšœ
        let byzantine_scenarios = vec![
            ("æ…¢å“åº”èŠ‚ç‚¹", "node_1", ByzantineType::SlowResponse),
            ("é”™è¯¯æ•°æ®èŠ‚ç‚¹", "node_2", ByzantineType::CorruptData),
            (
                "é—´æ­‡æ€§æ•…éšœèŠ‚ç‚¹",
                "node_3",
                ByzantineType::IntermittentFailure,
            ),
        ];

        for (scenario_name, node_id, byzantine_type) in byzantine_scenarios {
            println!("æµ‹è¯•åœºæ™¯: {}", scenario_name);

            // å¯ç”¨æ‹œå åº­è¡Œä¸º
            enable_byzantine_behavior(&cluster, node_id, byzantine_type).await;

            // åœ¨æ‹œå åº­æ•…éšœæœŸé—´æ‰§è¡Œæ“ä½œ
            let byzantine_doc =
                create_test_document_with_id(&format!("byzantine_test_{}", node_id));
            let write_result = cluster.insert_document(byzantine_doc.clone()).await;

            // éªŒè¯ç³»ç»Ÿå®¹é”™èƒ½åŠ›
            let read_result = cluster.get_document(&byzantine_doc.id).await;

            // æ‹œå åº­æ•…éšœä¸åº”è¯¥å½±å“ç³»ç»Ÿçš„æ•´ä½“æ­£ç¡®æ€§
            if write_result.is_ok() {
                assert!(read_result.is_ok(), "å†™å…¥æˆåŠŸçš„æ•°æ®åº”è¯¥èƒ½å¤Ÿè¯»å–");
            }

            // ç¦ç”¨æ‹œå åº­è¡Œä¸º
            disable_byzantine_behavior(&cluster, node_id).await;

            println!("  {} æµ‹è¯•å®Œæˆ", scenario_name);
        }

        // éªŒè¯ç³»ç»Ÿä»æ‹œå åº­æ•…éšœä¸­æ¢å¤
        assert!(cluster.is_available().await, "ç³»ç»Ÿåº”è¯¥ä»æ‹œå åº­æ•…éšœä¸­æ¢å¤");

        // éªŒè¯æ•°æ®ä¸€è‡´æ€§
        let consistency_check = verify_data_consistency(&cluster, &test_docs).await;
        assert!(
            consistency_check.is_consistent,
            "æ‹œå åº­æ•…éšœåæ•°æ®åº”è¯¥ä¿æŒä¸€è‡´"
        );

        println!("âœ… æ‹œå åº­æ•…éšœæµ‹è¯•é€šè¿‡");
    }

    #[tokio::test]
    async fn test_cascading_failures() {
        let cluster = TestCluster::new(ClusterType::SixNode).await;
        cluster.start_all_nodes().await.unwrap();

        println!("âš¡ çº§è”æ•…éšœæµ‹è¯•å¼€å§‹...");

        // å»ºç«‹é«˜è´Ÿè½½ç¯å¢ƒ
        let heavy_workload = WorkloadConfig {
            read_rate: 100,
            write_rate: 50,
            duration: Duration::from_secs(10),
            concurrent_connections: 30,
        };

        // å¯åŠ¨èƒŒæ™¯å·¥ä½œè´Ÿè½½
        let workload_handle = start_background_workload(&cluster, heavy_workload);

        // æ¨¡æ‹Ÿçº§è”æ•…éšœåºåˆ—
        println!("è§¦å‘çº§è”æ•…éšœåºåˆ—...");

        // ç¬¬ä¸€æ³¢ï¼šå•ä¸ªèŠ‚ç‚¹æ•…éšœ
        println!("ç¬¬ä¸€æ³¢æ•…éšœ: å•èŠ‚ç‚¹æ•…éšœ");
        cluster.stop_node("node_0").await.unwrap();
        tokio::time::sleep(Duration::from_millis(200)).await;

        let wave1_stats = cluster.get_cluster_stats().await;
        println!("ç¬¬ä¸€æ³¢åçŠ¶æ€: æ´»è·ƒèŠ‚ç‚¹ {}", wave1_stats.active_nodes);

        // ç¬¬äºŒæ³¢ï¼šç½‘ç»œåˆ†åŒºåŠ é‡è´Ÿè½½
        println!("ç¬¬äºŒæ³¢æ•…éšœ: ç½‘ç»œåˆ†åŒº");
        cluster
            .create_partition(vec![1, 2], vec![3, 4, 5])
            .await
            .unwrap();
        tokio::time::sleep(Duration::from_millis(300)).await;

        // ç¬¬ä¸‰æ³¢ï¼šé¢å¤–èŠ‚ç‚¹æ•…éšœ
        println!("ç¬¬ä¸‰æ³¢æ•…éšœ: åˆ†åŒºå†…èŠ‚ç‚¹æ•…éšœ");
        cluster.stop_node("node_4").await.unwrap();
        tokio::time::sleep(Duration::from_millis(200)).await;

        let wave3_stats = cluster.get_cluster_stats().await;
        println!("ç¬¬ä¸‰æ³¢åçŠ¶æ€: æ´»è·ƒèŠ‚ç‚¹ {}", wave3_stats.active_nodes);

        // éªŒè¯ç³»ç»Ÿæ˜¯å¦èƒ½é˜»æ­¢å®Œå…¨çº§è”å¤±æ•ˆ
        let final_availability = cluster.is_available().await;
        println!("çº§è”æ•…éšœåç³»ç»Ÿå¯ç”¨æ€§: {}", final_availability);

        // å¼€å§‹æ¢å¤åºåˆ—
        println!("å¼€å§‹æ¢å¤åºåˆ—...");

        // æ¢å¤ç½‘ç»œè¿æ¥
        cluster.heal_partition().await.unwrap();
        tokio::time::sleep(Duration::from_millis(300)).await;

        // é‡å¯æ•…éšœèŠ‚ç‚¹
        cluster.restart_node("node_0").await.unwrap();
        cluster.restart_node("node_4").await.unwrap();
        tokio::time::sleep(Duration::from_millis(500)).await;

        // åœæ­¢èƒŒæ™¯å·¥ä½œè´Ÿè½½
        workload_handle.abort();

        // éªŒè¯å®Œå…¨æ¢å¤
        let recovery_stats = cluster.get_cluster_stats().await;
        assert_eq!(recovery_stats.active_nodes, 6, "æ‰€æœ‰èŠ‚ç‚¹åº”è¯¥æ¢å¤");
        assert!(recovery_stats.is_healthy, "é›†ç¾¤åº”è¯¥å®Œå…¨å¥åº·");

        println!("âœ… çº§è”æ•…éšœæµ‹è¯•é€šè¿‡");
    }

    #[tokio::test]
    async fn test_data_corruption_scenarios() {
        let cluster = TestCluster::new(ClusterType::ThreeNode).await;
        cluster.start_all_nodes().await.unwrap();

        println!("ğŸ’½ æ•°æ®æŸååœºæ™¯æµ‹è¯•å¼€å§‹...");

        // æ’å…¥é‡è¦æ•°æ®
        let important_docs = generate_important_documents(30);
        for doc in &important_docs {
            cluster.insert_document(doc.clone()).await.unwrap();
        }

        // åœºæ™¯1ï¼šå•èŠ‚ç‚¹å­˜å‚¨æŸå
        println!("åœºæ™¯1: å•èŠ‚ç‚¹å­˜å‚¨æŸå");
        simulate_storage_corruption(&cluster, "node_2").await;

        // éªŒè¯ç³»ç»Ÿæ£€æµ‹å¹¶å¤„ç†æŸå
        let corruption_detected = detect_corruption(&cluster, "node_2").await;
        println!("æŸåæ£€æµ‹ç»“æœ: {}", corruption_detected);

        // éªŒè¯æ•°æ®ä»ç„¶å¯è®¿é—®ï¼ˆé€šè¿‡å‰¯æœ¬ï¼‰
        let mut accessible_after_corruption = 0;
        for doc in &important_docs[..10] {
            if cluster.get_document(&doc.id).await.is_ok() {
                accessible_after_corruption += 1;
            }
        }

        let corruption_resilience = accessible_after_corruption as f64 / 10.0;
        println!("æŸååæ•°æ®å¯è®¿é—®æ€§: {:.1}%", corruption_resilience * 100.0);

        // åœºæ™¯2ï¼šç´¢å¼•æŸå
        println!("åœºæ™¯2: ç´¢å¼•æŸå");
        simulate_index_corruption(&cluster).await;

        // éªŒè¯æœç´¢åŠŸèƒ½é™çº§ä½†ä¸å®Œå…¨å¤±æ•ˆ
        let search_result = perform_degraded_search(&cluster, "é‡è¦").await;
        println!("ç´¢å¼•æŸååæœç´¢ç»“æœ: {} ä¸ª", search_result.len());

        // åœºæ™¯3ï¼šè‡ªåŠ¨ä¿®å¤
        println!("åœºæ™¯3: è‡ªåŠ¨ä¿®å¤");
        let repair_result = trigger_auto_repair(&cluster).await;
        println!("è‡ªåŠ¨ä¿®å¤ç»“æœ: {}", repair_result);

        if repair_result {
            // éªŒè¯ä¿®å¤åçš„åŠŸèƒ½
            let mut recovered_after_repair = 0;
            for doc in &important_docs {
                if cluster.get_document(&doc.id).await.is_ok() {
                    recovered_after_repair += 1;
                }
            }

            let repair_effectiveness = recovered_after_repair as f64 / important_docs.len() as f64;
            println!("ä¿®å¤åæ•°æ®æ¢å¤ç‡: {:.1}%", repair_effectiveness * 100.0);

            assert!(repair_effectiveness >= 0.9, "è‡ªåŠ¨ä¿®å¤åº”è¯¥æ¢å¤è‡³å°‘90%çš„æ•°æ®");
        }

        // æ•°æ®æŸååœºæ™¯æ–­è¨€
        assert!(
            corruption_resilience >= 0.8,
            "å•èŠ‚ç‚¹æŸååè‡³å°‘80%æ•°æ®åº”è¯¥å¯è®¿é—®"
        );
        assert!(
            !search_result.is_empty() || repair_result,
            "æœç´¢åº”è¯¥é™çº§å¯ç”¨æˆ–èƒ½è‡ªåŠ¨ä¿®å¤"
        );

        println!("âœ… æ•°æ®æŸååœºæ™¯æµ‹è¯•é€šè¿‡");
    }

    #[tokio::test]
    async fn test_extreme_load_chaos() {
        let cluster = TestCluster::new(ClusterType::SixNode).await;
        cluster.start_all_nodes().await.unwrap();

        println!("ğŸš€ æé™è´Ÿè½½æ··æ²Œæµ‹è¯•å¼€å§‹...");

        // é…ç½®æé™è´Ÿè½½æ··æ²Œå®éªŒ
        let extreme_chaos = ChaosExperimentBuilder::new("extreme_load_chaos")
            .with_duration(Duration::from_secs(8))
            .with_failure_rate(0.2, 0.15) // é«˜æ•…éšœç‡
            .with_recovery_time(Duration::from_millis(100)) // å¿«é€Ÿæ¢å¤
            .with_network_chaos(NetworkChaos {
                packet_loss: 0.1,
                latency_spike: 500,
                partition_probability: 0.2,
            })
            .with_workload(WorkloadConfig {
                read_rate: 200,  // æé«˜è¯»å–ç‡
                write_rate: 100, // æé«˜å†™å…¥ç‡
                duration: Duration::from_secs(8),
                concurrent_connections: 50,
            })
            .build();

        // åŒæ—¶è¿è¡Œå¤šä¸ªå·¥ä½œè´Ÿè½½
        let workload_handles = vec![
            start_read_heavy_workload(&cluster, Duration::from_secs(8)),
            start_write_heavy_workload(&cluster, Duration::from_secs(8)),
            start_mixed_workload(&cluster, Duration::from_secs(8)),
        ];

        // æ‰§è¡Œæé™æ··æ²Œå®éªŒ
        let chaos_engine = cluster.chaos_engine();
        let experiment_result = chaos_engine.run_experiment(extreme_chaos).await.unwrap();

        // ç­‰å¾…æ‰€æœ‰å·¥ä½œè´Ÿè½½å®Œæˆ
        for handle in workload_handles {
            let _ = handle.await;
        }

        println!("æé™è´Ÿè½½æ··æ²Œå®éªŒç»“æœ:");
        println!("  å®éªŒæŒç»­æ—¶é—´: {:?}", experiment_result.duration);
        println!("  å®éªŒæˆåŠŸ: {}", experiment_result.success);
        println!(
            "  å¹³å‡å¯ç”¨æ€§: {:.3}",
            experiment_result.metrics.availability
        );
        println!(
            "  å¹³å‡è¯»å»¶è¿Ÿ: {:.2}ms",
            experiment_result.metrics.avg_read_latency_ms
        );
        println!(
            "  å¹³å‡å†™å»¶è¿Ÿ: {:.2}ms",
            experiment_result.metrics.avg_write_latency_ms
        );
        println!(
            "  ä¸€è‡´æ€§è¿å: {}",
            experiment_result.metrics.consistency_violations
        );
        println!(
            "  ç›‘æ§æ•°æ®ç‚¹: {}",
            experiment_result.metrics.total_data_points
        );

        // æé™è´Ÿè½½æ–­è¨€
        assert!(experiment_result.success, "æé™è´Ÿè½½å®éªŒåº”è¯¥æˆåŠŸå®Œæˆ");
        assert!(
            experiment_result.metrics.availability >= 0.6,
            "æé™è´Ÿè½½ä¸‹å¯ç”¨æ€§åº”è¯¥ >= 60%"
        );
        assert!(
            experiment_result.metrics.consistency_violations <= 5,
            "ä¸€è‡´æ€§è¿ååº”è¯¥å¾ˆå°‘"
        );

        // éªŒè¯ç³»ç»Ÿä»æé™è´Ÿè½½ä¸­æ¢å¤
        tokio::time::sleep(Duration::from_secs(1)).await;

        let post_chaos_stats = cluster.get_cluster_stats().await;
        assert!(post_chaos_stats.is_healthy, "æé™è´Ÿè½½åé›†ç¾¤åº”è¯¥æ¢å¤å¥åº·");

        // éªŒè¯åŸºæœ¬åŠŸèƒ½æ­£å¸¸
        let test_doc = create_test_document_with_id("post_chaos_test");
        cluster.insert_document(test_doc.clone()).await.unwrap();

        let retrieved = cluster.get_document("post_chaos_test").await.unwrap();
        assert_eq!(retrieved.id, "post_chaos_test");

        println!("âœ… æé™è´Ÿè½½æ··æ²Œæµ‹è¯•é€šè¿‡");
    }

    // è¾…åŠ©å‡½æ•°
    #[derive(Clone, Copy)]
    enum ByzantineType {
        SlowResponse,
        CorruptData,
        IntermittentFailure,
    }

    async fn enable_byzantine_behavior(
        cluster: &TestCluster,
        node_id: &str,
        byzantine_type: ByzantineType,
    ) {
        match byzantine_type {
            ByzantineType::SlowResponse => {
                println!("  å¯ç”¨æ…¢å“åº”æ¨¡å¼: {}", node_id);
                // åœ¨çœŸå®å®ç°ä¸­ä¼šå¢åŠ è¯¥èŠ‚ç‚¹çš„å“åº”å»¶è¿Ÿ
            }
            ByzantineType::CorruptData => {
                println!("  å¯ç”¨æ•°æ®æŸåæ¨¡å¼: {}", node_id);
                // åœ¨çœŸå®å®ç°ä¸­ä¼šè®©è¯¥èŠ‚ç‚¹è¿”å›é”™è¯¯æ•°æ®
            }
            ByzantineType::IntermittentFailure => {
                println!("  å¯ç”¨é—´æ­‡æ€§æ•…éšœæ¨¡å¼: {}", node_id);
                // åœ¨çœŸå®å®ç°ä¸­ä¼šè®©è¯¥èŠ‚ç‚¹éšæœºå¤±æ•ˆ
            }
        }
        tokio::time::sleep(Duration::from_millis(50)).await;
    }

    async fn disable_byzantine_behavior(cluster: &TestCluster, node_id: &str) {
        println!("  ç¦ç”¨æ‹œå åº­è¡Œä¸º: {}", node_id);
        tokio::time::sleep(Duration::from_millis(50)).await;
    }

    async fn verify_data_consistency(
        cluster: &TestCluster,
        docs: &[Document],
    ) -> ConsistencyResult {
        // ç®€åŒ–çš„ä¸€è‡´æ€§æ£€æŸ¥
        let mut consistent_docs = 0;
        let total_docs = docs.len().min(10); // æ£€æŸ¥å‰10ä¸ªæ–‡æ¡£

        for doc in &docs[..total_docs] {
            if cluster.get_document(&doc.id).await.is_ok() {
                consistent_docs += 1;
            }
        }

        ConsistencyResult {
            is_consistent: consistent_docs == total_docs,
            consistency_ratio: consistent_docs as f64 / total_docs as f64,
            checked_documents: total_docs,
        }
    }

    fn start_background_workload(
        cluster: &TestCluster,
        workload: WorkloadConfig,
    ) -> tokio::task::JoinHandle<()> {
        let cluster = cluster.clone();
        tokio::spawn(async move {
            let end_time = std::time::Instant::now() + workload.duration;
            let mut operation_count = 0;

            while std::time::Instant::now() < end_time {
                // æ··åˆè¯»å†™æ“ä½œ
                if operation_count % 3 == 0 {
                    // å†™æ“ä½œ
                    let doc = create_test_document_with_id(&format!("bg_doc_{}", operation_count));
                    let _ = cluster.insert_document(doc).await;
                } else {
                    // è¯»æ“ä½œ
                    let doc_id = format!("bg_doc_{}", operation_count % 100);
                    let _ = cluster.get_document(&doc_id).await;
                }

                operation_count += 1;
                tokio::time::sleep(Duration::from_millis(20)).await;
            }
        })
    }

    async fn simulate_storage_corruption(cluster: &TestCluster, node_id: &str) {
        println!("  æ¨¡æ‹ŸèŠ‚ç‚¹ {} å­˜å‚¨æŸå", node_id);
        tokio::time::sleep(Duration::from_millis(100)).await;
    }

    async fn detect_corruption(cluster: &TestCluster, node_id: &str) -> bool {
        tokio::time::sleep(Duration::from_millis(50)).await;
        true // æ¨¡æ‹Ÿæ£€æµ‹åˆ°æŸå
    }

    async fn simulate_index_corruption(cluster: &TestCluster) {
        println!("  æ¨¡æ‹Ÿç´¢å¼•æŸå");
        tokio::time::sleep(Duration::from_millis(100)).await;
    }

    async fn perform_degraded_search(cluster: &TestCluster, query: &str) -> Vec<SearchResult> {
        tokio::time::sleep(Duration::from_millis(50)).await;

        // æ¨¡æ‹Ÿé™çº§æœç´¢ï¼šè¿”å›éƒ¨åˆ†ç»“æœ
        let now = chrono::Utc::now();
        let document = DocumentRecord {
            id: "degraded_result".to_string(),
            content: "degraded search result".to_string(),
            title: "Degraded Result".to_string(),
            language: "zh".to_string(),
            package_name: "test".to_string(),
            version: "1.0".to_string(),
            doc_type: "test".to_string(),
            vector: None,
            metadata: HashMap::new(),
            embedding: vec![0.1; 768], // dummy embedding
            sparse_representation: None,
            created_at: now,
            updated_at: now,
        };
        
        vec![SearchResult {
            document,
            score: 0.7,
            relevance_score: Some(0.7),
            matched_snippets: Some(vec!["degraded search result".to_string()]),
        }]
    }

    async fn trigger_auto_repair(cluster: &TestCluster) -> bool {
        println!("  è§¦å‘è‡ªåŠ¨ä¿®å¤...");
        tokio::time::sleep(Duration::from_millis(200)).await;
        true // æ¨¡æ‹Ÿä¿®å¤æˆåŠŸ
    }

    fn start_read_heavy_workload(
        cluster: &TestCluster,
        duration: Duration,
    ) -> tokio::task::JoinHandle<()> {
        let cluster = cluster.clone();
        tokio::spawn(async move {
            let end_time = std::time::Instant::now() + duration;
            while std::time::Instant::now() < end_time {
                let doc_id = format!("doc_{}", fastrand::u32(0..100));
                let _ = cluster.get_document(&doc_id).await;
                tokio::time::sleep(Duration::from_millis(5)).await;
            }
        })
    }

    fn start_write_heavy_workload(
        cluster: &TestCluster,
        duration: Duration,
    ) -> tokio::task::JoinHandle<()> {
        let cluster = cluster.clone();
        tokio::spawn(async move {
            let end_time = std::time::Instant::now() + duration;
            let mut counter = 0;
            while std::time::Instant::now() < end_time {
                let doc = create_test_document_with_id(&format!("heavy_write_{}", counter));
                let _ = cluster.insert_document(doc).await;
                counter += 1;
                tokio::time::sleep(Duration::from_millis(10)).await;
            }
        })
    }

    fn start_mixed_workload(
        cluster: &TestCluster,
        duration: Duration,
    ) -> tokio::task::JoinHandle<()> {
        let cluster = cluster.clone();
        tokio::spawn(async move {
            let end_time = std::time::Instant::now() + duration;
            let mut counter = 0;
            while std::time::Instant::now() < end_time {
                if counter % 2 == 0 {
                    let doc = create_test_document_with_id(&format!("mixed_{}", counter));
                    let _ = cluster.insert_document(doc).await;
                } else {
                    let doc_id = format!("mixed_{}", counter - 1);
                    let _ = cluster.get_document(&doc_id).await;
                }
                counter += 1;
                tokio::time::sleep(Duration::from_millis(8)).await;
            }
        })
    }

    fn generate_critical_documents(count: usize) -> Vec<Document> {
        (0..count)
            .map(|i| {
                let mut doc = create_test_document_with_id(&format!("critical_doc_{}", i));
                doc.content = format!("è¿™æ˜¯å…³é”®ä¸šåŠ¡æ•°æ® {}", i);
                let mut metadata = HashMap::new();
                metadata.insert("priority".to_string(), "critical".to_string());
                metadata.insert("backup_required".to_string(), "true".to_string());
                doc.metadata = metadata;
                doc
            })
            .collect()
    }

    fn generate_important_documents(count: usize) -> Vec<Document> {
        (0..count)
            .map(|i| {
                let mut doc = create_test_document_with_id(&format!("important_doc_{}", i));
                doc.content = format!("è¿™æ˜¯é‡è¦æ•°æ®æ–‡æ¡£ {}", i);
                let mut metadata = HashMap::new();
                metadata.insert("importance".to_string(), "high".to_string());
                doc.metadata = metadata;
                doc
            })
            .collect()
    }
}

// è¾…åŠ©ç±»å‹
#[derive(Debug)]
struct ConsistencyResult {
    is_consistent: bool,
    consistency_ratio: f64,
    checked_documents: usize,
}

// è¿è¡Œæ‰€æœ‰æµ‹è¯•çš„è¾…åŠ©å‡½æ•°
#[tokio::test]
async fn run_all_chaos_tests() {
    tracing_subscriber::fmt::init();

    println!("å¼€å§‹è¿è¡Œæ··æ²Œå·¥ç¨‹ç»¼åˆæµ‹è¯•...");
    println!("{}", "=".repeat(60));

    // æ³¨æ„ï¼šåœ¨å®é™…æµ‹è¯•ä¸­ï¼Œè¿™äº›æµ‹è¯•æ¨¡å—ä¼šè‡ªåŠ¨è¿è¡Œ
    // è¿™é‡Œåªæ˜¯ä¸€ä¸ªå ä½ç¬¦å‡½æ•°æ¥ç»„ç»‡æµ‹è¯•ç»“æ„

    println!("æ‰€æœ‰æ··æ²Œå·¥ç¨‹æµ‹è¯•å®Œæˆï¼");
}
