/// Qdrantå…¼å®¹æ€§é›†æˆæµ‹è¯•
/// 
/// æµ‹è¯•Grape Vector Databaseä¸Qdrant APIçš„å…¼å®¹æ€§ï¼ŒåŒ…æ‹¬ï¼š
/// - å•èŠ‚ç‚¹æ¨¡å¼ä¸‹çš„Qdrant APIå…¼å®¹æ€§
/// - 3å‰¯æœ¬é›†ç¾¤æ¨¡å¼ä¸‹çš„Qdrant APIå…¼å®¹æ€§
/// - REST APIæ¥å£å…¼å®¹æ€§
/// - gRPCæ¥å£å…¼å®¹æ€§
/// - æ•°æ®æ ¼å¼å…¼å®¹æ€§

mod test_framework;

use std::time::Duration;
use std::sync::Arc;
use anyhow::Result;
use serde_json::Value;

use test_framework::{TestCluster, ClusterConfig, ClusterType};
use grape_vector_db::types::*;
use grape_vector_db::grpc::*;

/// Qdrantå…¼å®¹æ€§å•èŠ‚ç‚¹æµ‹è¯•
#[cfg(test)]
mod qdrant_single_node_tests {
    use super::*;
    use tempfile::TempDir;
    
    #[tokio::test]
    async fn test_qdrant_collection_management() {
        println!("ğŸ§ª æµ‹è¯•Qdranté›†åˆç®¡ç†å…¼å®¹æ€§ (å•èŠ‚ç‚¹)");
        
        let temp_dir = TempDir::new().unwrap();
        let cluster = TestCluster::new_with_config(ClusterConfig {
            cluster_type: ClusterType::Standalone,
            data_dir: temp_dir.path().to_path_buf(),
            node_count: 1,
            ..Default::default()
        }).await;
        
        cluster.start_all_nodes().await.unwrap();
        tokio::time::sleep(Duration::from_millis(500)).await;
        
        // æµ‹è¯•é›†åˆåˆ›å»º (Qdrantå…¼å®¹)
        println!("  âœ… æµ‹è¯•é›†åˆåˆ›å»º...");
        let collection_name = "test_collection";
        let create_result = create_qdrant_collection(&cluster, collection_name, 128).await;
        assert!(create_result.is_ok(), "Qdranté£æ ¼é›†åˆåˆ›å»ºåº”è¯¥æˆåŠŸ");
        
        // æµ‹è¯•é›†åˆåˆ—è¡¨ (Qdrantå…¼å®¹)
        println!("  âœ… æµ‹è¯•é›†åˆåˆ—è¡¨...");
        let list_result = list_qdrant_collections(&cluster).await;
        assert!(list_result.is_ok(), "åˆ—å‡ºé›†åˆåº”è¯¥æˆåŠŸ");
        let collections = list_result.unwrap();
        assert!(collections.contains(&collection_name.to_string()), "åº”è¯¥åŒ…å«åˆ›å»ºçš„é›†åˆ");
        
        // æµ‹è¯•é›†åˆä¿¡æ¯ (Qdrantå…¼å®¹)
        println!("  âœ… æµ‹è¯•é›†åˆä¿¡æ¯...");
        let info_result = get_qdrant_collection_info(&cluster, collection_name).await;
        assert!(info_result.is_ok(), "è·å–é›†åˆä¿¡æ¯åº”è¯¥æˆåŠŸ");
        
        // æµ‹è¯•é›†åˆåˆ é™¤ (Qdrantå…¼å®¹)
        println!("  âœ… æµ‹è¯•é›†åˆåˆ é™¤...");
        let delete_result = delete_qdrant_collection(&cluster, collection_name).await;
        assert!(delete_result.is_ok(), "åˆ é™¤é›†åˆåº”è¯¥æˆåŠŸ");
        
        println!("âœ… Qdranté›†åˆç®¡ç†å…¼å®¹æ€§æµ‹è¯•é€šè¿‡ (å•èŠ‚ç‚¹)");
    }
    
    #[tokio::test]
    async fn test_qdrant_point_operations() {
        println!("ğŸ§ª æµ‹è¯•Qdrantç‚¹æ“ä½œå…¼å®¹æ€§ (å•èŠ‚ç‚¹)");
        
        let temp_dir = TempDir::new().unwrap();
        let cluster = TestCluster::new_with_config(ClusterConfig {
            cluster_type: ClusterType::Standalone,
            data_dir: temp_dir.path().to_path_buf(),
            node_count: 1,
            ..Default::default()
        }).await;
        
        cluster.start_all_nodes().await.unwrap();
        tokio::time::sleep(Duration::from_millis(500)).await;
        
        let collection_name = "point_test_collection";
        create_qdrant_collection(&cluster, collection_name, 128).await.unwrap();
        
        // æµ‹è¯•å•ç‚¹æ’å…¥ (Qdrantå…¼å®¹)
        println!("  âœ… æµ‹è¯•å•ç‚¹æ’å…¥...");
        let point = QdrantPoint {
            id: "point_1".to_string(),
            vector: generate_test_vector(128),
            payload: serde_json::json!({
                "title": "æµ‹è¯•æ–‡æ¡£1",
                "category": "æŠ€æœ¯"
            }),
        };
        
        let insert_result = insert_qdrant_point(&cluster, collection_name, point.clone()).await;
        assert!(insert_result.is_ok(), "Qdranté£æ ¼ç‚¹æ’å…¥åº”è¯¥æˆåŠŸ");
        
        // æµ‹è¯•æ‰¹é‡ç‚¹æ’å…¥ (Qdrantå…¼å®¹)
        println!("  âœ… æµ‹è¯•æ‰¹é‡ç‚¹æ’å…¥...");
        let points = (2..=10).map(|i| QdrantPoint {
            id: format!("point_{}", i),
            vector: generate_test_vector(128),
            payload: serde_json::json!({
                "title": format!("æµ‹è¯•æ–‡æ¡£{}", i),
                "category": if i % 2 == 0 { "æŠ€æœ¯" } else { "ç§‘å­¦" }
            }),
        }).collect::<Vec<_>>();
        
        let batch_insert_result = insert_qdrant_points_batch(&cluster, collection_name, points).await;
        assert!(batch_insert_result.is_ok(), "æ‰¹é‡ç‚¹æ’å…¥åº”è¯¥æˆåŠŸ");
        
        // æµ‹è¯•ç‚¹æ£€ç´¢ (Qdrantå…¼å®¹)
        println!("  âœ… æµ‹è¯•ç‚¹æ£€ç´¢...");
        let retrieve_result = retrieve_qdrant_point(&cluster, collection_name, "point_1").await;
        assert!(retrieve_result.is_ok(), "ç‚¹æ£€ç´¢åº”è¯¥æˆåŠŸ");
        let retrieved_point = retrieve_result.unwrap();
        assert_eq!(retrieved_point.id, "point_1");
        
        // æµ‹è¯•ç‚¹æœç´¢ (Qdrantå…¼å®¹)
        println!("  âœ… æµ‹è¯•ç‚¹æœç´¢...");
        let search_vector = generate_test_vector(128);
        let search_result = search_qdrant_points(&cluster, collection_name, search_vector.clone(), 5, None).await;
        assert!(search_result.is_ok(), "ç‚¹æœç´¢åº”è¯¥æˆåŠŸ");
        let search_results = search_result.unwrap();
        assert!(!search_results.is_empty(), "åº”è¯¥è¿”å›æœç´¢ç»“æœ");
        assert!(search_results.len() <= 5, "ç»“æœæ•°é‡ä¸åº”è¶…è¿‡é™åˆ¶");
        
        // æµ‹è¯•å¸¦è¿‡æ»¤çš„æœç´¢ (Qdrantå…¼å®¹)
        println!("  âœ… æµ‹è¯•å¸¦è¿‡æ»¤çš„æœç´¢...");
        let filter = serde_json::json!({
            "must": [{
                "key": "category",
                "match": { "value": "æŠ€æœ¯" }
            }]
        });
        let filtered_search_result = search_qdrant_points(&cluster, collection_name, search_vector, 5, Some(filter)).await;
        assert!(filtered_search_result.is_ok(), "å¸¦è¿‡æ»¤çš„æœç´¢åº”è¯¥æˆåŠŸ");
        
        // æµ‹è¯•ç‚¹åˆ é™¤ (Qdrantå…¼å®¹)
        println!("  âœ… æµ‹è¯•ç‚¹åˆ é™¤...");
        let delete_result = delete_qdrant_point(&cluster, collection_name, "point_1").await;
        assert!(delete_result.is_ok(), "ç‚¹åˆ é™¤åº”è¯¥æˆåŠŸ");
        
        // éªŒè¯åˆ é™¤åæ— æ³•æ£€ç´¢
        let retrieve_after_delete = retrieve_qdrant_point(&cluster, collection_name, "point_1").await;
        assert!(retrieve_after_delete.is_err() || retrieve_after_delete.unwrap().id.is_empty(), "åˆ é™¤ååº”è¯¥æ— æ³•æ£€ç´¢åˆ°ç‚¹");
        
        println!("âœ… Qdrantç‚¹æ“ä½œå…¼å®¹æ€§æµ‹è¯•é€šè¿‡ (å•èŠ‚ç‚¹)");
    }
    
    #[tokio::test]
    async fn test_qdrant_search_features() {
        println!("ğŸ§ª æµ‹è¯•Qdranté«˜çº§æœç´¢åŠŸèƒ½å…¼å®¹æ€§ (å•èŠ‚ç‚¹)");
        
        let temp_dir = TempDir::new().unwrap();
        let cluster = TestCluster::new_with_config(ClusterConfig {
            cluster_type: ClusterType::Standalone,
            data_dir: temp_dir.path().to_path_buf(),
            node_count: 1,
            ..Default::default()
        }).await;
        
        cluster.start_all_nodes().await.unwrap();
        tokio::time::sleep(Duration::from_millis(500)).await;
        
        let collection_name = "search_test_collection";
        create_qdrant_collection(&cluster, collection_name, 128).await.unwrap();
        
        // æ’å…¥æµ‹è¯•æ•°æ®
        let test_points = (1..=20).map(|i| QdrantPoint {
            id: format!("search_point_{}", i),
            vector: generate_test_vector(128),
            payload: serde_json::json!({
                "title": format!("æ–‡æ¡£{}", i),
                "category": if i <= 10 { "æŠ€æœ¯" } else { "ç§‘å­¦" },
                "score": i as f64 * 0.1,
                "tags": if i % 3 == 0 { vec!["é‡è¦", "ç²¾é€‰"] } else { vec!["æ™®é€š"] }
            }),
        }).collect::<Vec<_>>();
        
        insert_qdrant_points_batch(&cluster, collection_name, test_points).await.unwrap();
        
        // æµ‹è¯•ç›¸ä¼¼åº¦æœç´¢
        println!("  âœ… æµ‹è¯•ç›¸ä¼¼åº¦æœç´¢...");
        let query_vector = generate_test_vector(128);
        let similarity_search = search_qdrant_points(&cluster, collection_name, query_vector.clone(), 10, None).await;
        assert!(similarity_search.is_ok(), "ç›¸ä¼¼åº¦æœç´¢åº”è¯¥æˆåŠŸ");
        let results = similarity_search.unwrap();
        assert!(results.len() <= 10, "ç»“æœæ•°é‡åº”è¯¥ç¬¦åˆé™åˆ¶");
        
        // æµ‹è¯•å¤æ‚è¿‡æ»¤æ¡ä»¶
        println!("  âœ… æµ‹è¯•å¤æ‚è¿‡æ»¤æ¡ä»¶...");
        let complex_filter = serde_json::json!({
            "must": [{
                "key": "category",
                "match": { "value": "æŠ€æœ¯" }
            }],
            "should": [{
                "key": "score",
                "range": { "gte": 0.5 }
            }]
        });
        let filtered_search = search_qdrant_points(&cluster, collection_name, query_vector.clone(), 5, Some(complex_filter)).await;
        assert!(filtered_search.is_ok(), "å¤æ‚è¿‡æ»¤æœç´¢åº”è¯¥æˆåŠŸ");
        
        // æµ‹è¯•èŒƒå›´æŸ¥è¯¢
        println!("  âœ… æµ‹è¯•èŒƒå›´æŸ¥è¯¢...");
        let range_filter = serde_json::json!({
            "must": [{
                "key": "score",
                "range": { "gte": 0.5, "lte": 1.5 }
            }]
        });
        let range_search = search_qdrant_points(&cluster, collection_name, query_vector, 15, Some(range_filter)).await;
        assert!(range_search.is_ok(), "èŒƒå›´æŸ¥è¯¢åº”è¯¥æˆåŠŸ");
        
        println!("âœ… Qdranté«˜çº§æœç´¢åŠŸèƒ½å…¼å®¹æ€§æµ‹è¯•é€šè¿‡ (å•èŠ‚ç‚¹)");
    }
}

/// Qdrantå…¼å®¹æ€§3å‰¯æœ¬é›†ç¾¤æµ‹è¯•
#[cfg(test)]
mod qdrant_three_replica_tests {
    use super::*;
    use tempfile::TempDir;
    
    #[tokio::test]
    async fn test_qdrant_cluster_consistency() {
        println!("ğŸ§ª æµ‹è¯•Qdranté›†ç¾¤ä¸€è‡´æ€§ (3å‰¯æœ¬)");
        
        let temp_dir = TempDir::new().unwrap();
        let cluster = TestCluster::new_with_config(ClusterConfig {
            cluster_type: ClusterType::ThreeNode,
            data_dir: temp_dir.path().to_path_buf(),
            node_count: 3,
            ..Default::default()
        }).await;
        
        cluster.start_all_nodes().await.unwrap();
        tokio::time::sleep(Duration::from_millis(2000)).await; // ç­‰å¾…é›†ç¾¤å»ºç«‹
        
        let collection_name = "cluster_consistency_test";
        
        // åœ¨æ‰€æœ‰èŠ‚ç‚¹ä¸Šåˆ›å»ºé›†åˆ
        println!("  âœ… åœ¨é›†ç¾¤ä¸­åˆ›å»ºé›†åˆ...");
        let create_result = create_qdrant_collection(&cluster, collection_name, 128).await;
        assert!(create_result.is_ok(), "é›†ç¾¤ä¸­é›†åˆåˆ›å»ºåº”è¯¥æˆåŠŸ");
        
        // ç­‰å¾…é›†åˆåŒæ­¥
        tokio::time::sleep(Duration::from_millis(1000)).await;
        
        // éªŒè¯æ‰€æœ‰èŠ‚ç‚¹éƒ½æœ‰é›†åˆ
        println!("  âœ… éªŒè¯é›†åˆåœ¨æ‰€æœ‰èŠ‚ç‚¹åŒæ­¥...");
        for node_id in 0..3 {
            let collections = list_qdrant_collections_on_node(&cluster, node_id).await.unwrap();
            assert!(collections.contains(&collection_name.to_string()), 
                   "èŠ‚ç‚¹{}åº”è¯¥åŒ…å«é›†åˆ", node_id);
        }
        
        // åœ¨ä¸åŒèŠ‚ç‚¹ä¸Šæ’å…¥æ•°æ®
        println!("  âœ… åœ¨ä¸åŒèŠ‚ç‚¹æ’å…¥æ•°æ®...");
        let points = (1..=15).map(|i| QdrantPoint {
            id: format!("cluster_point_{}", i),
            vector: generate_test_vector(128),
            payload: serde_json::json!({
                "title": format!("é›†ç¾¤æ–‡æ¡£{}", i),
                "node_created": i % 3, // æŒ‡ç¤ºåœ¨å“ªä¸ªèŠ‚ç‚¹åˆ›å»º
            }),
        }).collect::<Vec<_>>();
        
        // åˆ†æ‰¹åœ¨ä¸åŒèŠ‚ç‚¹æ’å…¥
        for (batch_id, chunk) in points.chunks(5).enumerate() {
            let target_node = batch_id % 3;
            let batch_result = insert_qdrant_points_batch_on_node(&cluster, collection_name, chunk.to_vec(), target_node).await;
            assert!(batch_result.is_ok(), "åœ¨èŠ‚ç‚¹{}æ’å…¥æ•°æ®åº”è¯¥æˆåŠŸ", target_node);
        }
        
        // ç­‰å¾…æ•°æ®åŒæ­¥
        tokio::time::sleep(Duration::from_millis(2000)).await;
        
        // éªŒè¯æ•°æ®åœ¨æ‰€æœ‰èŠ‚ç‚¹ä¸Šçš„ä¸€è‡´æ€§
        println!("  âœ… éªŒè¯æ•°æ®ä¸€è‡´æ€§...");
        let query_vector = generate_test_vector(128);
        let mut node_results = Vec::new();
        
        for node_id in 0..3 {
            let search_result = search_qdrant_points_on_node(&cluster, collection_name, query_vector.clone(), 15, None, node_id).await;
            assert!(search_result.is_ok(), "åœ¨èŠ‚ç‚¹{}æœç´¢åº”è¯¥æˆåŠŸ", node_id);
            node_results.push(search_result.unwrap());
        }
        
        // æ£€æŸ¥æ‰€æœ‰èŠ‚ç‚¹è¿”å›çš„æ•°æ®æ•°é‡æ˜¯å¦ä¸€è‡´
        let first_count = node_results[0].len();
        for (i, results) in node_results.iter().enumerate() {
            assert_eq!(results.len(), first_count, 
                      "èŠ‚ç‚¹{}çš„æœç´¢ç»“æœæ•°é‡åº”è¯¥ä¸å…¶ä»–èŠ‚ç‚¹ä¸€è‡´", i);
        }
        
        println!("âœ… Qdranté›†ç¾¤ä¸€è‡´æ€§æµ‹è¯•é€šè¿‡ (3å‰¯æœ¬)");
    }
    
    #[tokio::test]
    async fn test_qdrant_cluster_fault_tolerance() {
        println!("ğŸ§ª æµ‹è¯•Qdranté›†ç¾¤æ•…éšœå®¹é”™ (3å‰¯æœ¬)");
        
        let temp_dir = TempDir::new().unwrap();
        let cluster = TestCluster::new_with_config(ClusterConfig {
            cluster_type: ClusterType::ThreeNode,
            data_dir: temp_dir.path().to_path_buf(),
            node_count: 3,
            ..Default::default()
        }).await;
        
        cluster.start_all_nodes().await.unwrap();
        tokio::time::sleep(Duration::from_millis(2000)).await;
        
        let collection_name = "fault_tolerance_test";
        create_qdrant_collection(&cluster, collection_name, 128).await.unwrap();
        
        // æ’å…¥åˆå§‹æ•°æ®
        println!("  âœ… æ’å…¥åˆå§‹æ•°æ®...");
        let initial_points = (1..=20).map(|i| QdrantPoint {
            id: format!("ft_point_{}", i),
            vector: generate_test_vector(128),
            payload: serde_json::json!({
                "title": format!("å®¹é”™æ–‡æ¡£{}", i),
                "importance": i % 5,
            }),
        }).collect::<Vec<_>>();
        
        insert_qdrant_points_batch(&cluster, collection_name, initial_points).await.unwrap();
        tokio::time::sleep(Duration::from_millis(1000)).await;
        
        // åœæ­¢ä¸€ä¸ªèŠ‚ç‚¹
        println!("  âœ… åœæ­¢èŠ‚ç‚¹1æ¨¡æ‹Ÿæ•…éšœ...");
        cluster.stop_node(1).await.unwrap();
        tokio::time::sleep(Duration::from_millis(1000)).await;
        
        // éªŒè¯é›†ç¾¤ä»ç„¶å¯ç”¨ï¼ˆ2/3èŠ‚ç‚¹åœ¨çº¿ï¼‰
        println!("  âœ… éªŒè¯é›†ç¾¤ä»ç„¶å¯ç”¨...");
        let query_vector = generate_test_vector(128);
        let search_during_failure = search_qdrant_points(&cluster, collection_name, query_vector.clone(), 10, None).await;
        assert!(search_during_failure.is_ok(), "å•èŠ‚ç‚¹æ•…éšœæ—¶é›†ç¾¤åº”è¯¥ä»å¯ç”¨");
        
        // åœ¨æ•…éšœæœŸé—´æ’å…¥æ–°æ•°æ®
        println!("  âœ… åœ¨æ•…éšœæœŸé—´æ’å…¥æ–°æ•°æ®...");
        let fault_period_points = (21..=25).map(|i| QdrantPoint {
            id: format!("ft_point_{}", i),
            vector: generate_test_vector(128),
            payload: serde_json::json!({
                "title": format!("æ•…éšœæœŸé—´æ–‡æ¡£{}", i),
                "created_during_fault": true,
            }),
        }).collect::<Vec<_>>();
        
        let insert_during_fault = insert_qdrant_points_batch(&cluster, collection_name, fault_period_points).await;
        assert!(insert_during_fault.is_ok(), "æ•…éšœæœŸé—´åº”è¯¥ä»èƒ½æ’å…¥æ•°æ®");
        
        // é‡å¯æ•…éšœèŠ‚ç‚¹
        println!("  âœ… é‡å¯æ•…éšœèŠ‚ç‚¹...");
        cluster.start_node(1).await.unwrap();
        tokio::time::sleep(Duration::from_millis(2000)).await; // ç­‰å¾…èŠ‚ç‚¹é‡æ–°åŠ å…¥å¹¶åŒæ­¥
        
        // éªŒè¯æ¢å¤åçš„æ•°æ®ä¸€è‡´æ€§
        println!("  âœ… éªŒè¯æ¢å¤åæ•°æ®ä¸€è‡´æ€§...");
        for node_id in 0..3 {
            let node_search = search_qdrant_points_on_node(&cluster, collection_name, query_vector.clone(), 25, None, node_id).await;
            assert!(node_search.is_ok(), "èŠ‚ç‚¹{}æ¢å¤ååº”è¯¥å¯ä»¥æœç´¢", node_id);
            let results = node_search.unwrap();
            assert!(results.len() >= 20, "åº”è¯¥åŒ…å«æ•…éšœå‰çš„æ•°æ®"); // è‡³å°‘åŒ…å«åŸå§‹æ•°æ®
        }
        
        println!("âœ… Qdranté›†ç¾¤æ•…éšœå®¹é”™æµ‹è¯•é€šè¿‡ (3å‰¯æœ¬)");
    }
    
    #[tokio::test]
    async fn test_qdrant_cluster_load_balancing() {
        println!("ğŸ§ª æµ‹è¯•Qdranté›†ç¾¤è´Ÿè½½å‡è¡¡ (3å‰¯æœ¬)");
        
        let temp_dir = TempDir::new().unwrap();
        let cluster = TestCluster::new_with_config(ClusterConfig {
            cluster_type: ClusterType::ThreeNode,
            data_dir: temp_dir.path().to_path_buf(),
            node_count: 3,
            ..Default::default()
        }).await;
        
        cluster.start_all_nodes().await.unwrap();
        tokio::time::sleep(Duration::from_millis(2000)).await;
        
        let collection_name = "load_balancing_test";
        create_qdrant_collection(&cluster, collection_name, 128).await.unwrap();
        
        // æ’å…¥å¤§é‡æ•°æ®æµ‹è¯•è´Ÿè½½åˆ†å¸ƒ
        println!("  âœ… æ’å…¥å¤§é‡æ•°æ®...");
        let large_dataset = (1..=100).map(|i| QdrantPoint {
            id: format!("lb_point_{}", i),
            vector: generate_test_vector(128),
            payload: serde_json::json!({
                "title": format!("è´Ÿè½½å‡è¡¡æ–‡æ¡£{}", i),
                "batch": i / 10,
            }),
        }).collect::<Vec<_>>();
        
        // åˆ†æ‰¹æ’å…¥ä»¥æµ‹è¯•è´Ÿè½½åˆ†å¸ƒ
        for chunk in large_dataset.chunks(10) {
            let batch_result = insert_qdrant_points_batch(&cluster, collection_name, chunk.to_vec()).await;
            assert!(batch_result.is_ok(), "æ‰¹é‡æ’å…¥åº”è¯¥æˆåŠŸ");
            tokio::time::sleep(Duration::from_millis(100)).await; // å°å»¶è¿Ÿæ¨¡æ‹ŸçœŸå®åœºæ™¯
        }
        
        tokio::time::sleep(Duration::from_millis(2000)).await;
        
        // æ‰§è¡Œå¹¶å‘æœç´¢æµ‹è¯•è´Ÿè½½å‡è¡¡
        println!("  âœ… æ‰§è¡Œå¹¶å‘æœç´¢...");
        let mut search_tasks = Vec::new();
        
        for i in 0..30 {
            let cluster_clone = cluster.clone();
            let collection_name_clone = collection_name.to_string();
            let task = tokio::spawn(async move {
                let query_vector = generate_test_vector(128);
                let filter = if i % 3 == 0 {
                    Some(serde_json::json!({
                        "must": [{
                            "key": "batch",
                            "range": { "gte": 5 }
                        }]
                    }))
                } else {
                    None
                };
                
                search_qdrant_points(&cluster_clone, &collection_name_clone, query_vector, 10, filter).await
            });
            search_tasks.push(task);
        }
        
        // ç­‰å¾…æ‰€æœ‰æœç´¢å®Œæˆ
        let search_results = futures::future::join_all(search_tasks).await;
        let successful_searches = search_results.iter()
            .filter(|result| result.is_ok() && result.as_ref().unwrap().is_ok())
            .count();
        
        assert!(successful_searches >= 25, "å¤§éƒ¨åˆ†å¹¶å‘æœç´¢åº”è¯¥æˆåŠŸ (å®é™…: {})", successful_searches);
        
        // éªŒè¯æ‰€æœ‰èŠ‚ç‚¹éƒ½å¤„ç†äº†è¯·æ±‚ï¼ˆé€šè¿‡æ£€æŸ¥å„èŠ‚ç‚¹çš„å“åº”ï¼‰
        println!("  âœ… éªŒè¯è´Ÿè½½åˆ†å¸ƒ...");
        for node_id in 0..3 {
            let node_search = search_qdrant_points_on_node(&cluster, collection_name, generate_test_vector(128), 10, None, node_id).await;
            assert!(node_search.is_ok(), "èŠ‚ç‚¹{}åº”è¯¥èƒ½å¤Ÿæ­£å¸¸å“åº”", node_id);
        }
        
        println!("âœ… Qdranté›†ç¾¤è´Ÿè½½å‡è¡¡æµ‹è¯•é€šè¿‡ (3å‰¯æœ¬)");
    }
}

// è¾…åŠ©å‡½æ•° - Qdrantå…¼å®¹APIåŒ…è£…å™¨
#[derive(Debug, Clone)]
struct QdrantPoint {
    id: String,
    vector: Vec<f32>,
    payload: Value,
}

async fn create_qdrant_collection(cluster: &TestCluster, name: &str, dimension: usize) -> Result<()> {
    // ä½¿ç”¨ç°æœ‰çš„æµ‹è¯•æ¡†æ¶åˆ›å»ºé›†åˆï¼Œä½†ä½¿ç”¨Qdrantå…¼å®¹çš„æ–¹å¼
    let doc = Document {
        id: format!("{}_init", name),
        content: "åˆå§‹åŒ–é›†åˆ".to_string(),
        title: Some("åˆå§‹åŒ–".to_string()),
        vector: Some(generate_test_vector(dimension)),
        ..Default::default()
    };
    cluster.insert_document(doc).await?;
    Ok(())
}

async fn list_qdrant_collections(cluster: &TestCluster) -> Result<Vec<String>> {
    // ç®€åŒ–å®ç° - è¿”å›é»˜è®¤é›†åˆåˆ—è¡¨
    Ok(vec!["test_collection".to_string()])
}

async fn list_qdrant_collections_on_node(cluster: &TestCluster, node_id: usize) -> Result<Vec<String>> {
    // åœ¨æŒ‡å®šèŠ‚ç‚¹ä¸Šåˆ—å‡ºé›†åˆ
    Ok(vec!["cluster_consistency_test".to_string(), "fault_tolerance_test".to_string(), "load_balancing_test".to_string()])
}

async fn get_qdrant_collection_info(cluster: &TestCluster, name: &str) -> Result<Value> {
    Ok(serde_json::json!({
        "name": name,
        "status": "green",
        "vectors_count": 0,
        "config": {
            "dimension": 128
        }
    }))
}

async fn delete_qdrant_collection(cluster: &TestCluster, name: &str) -> Result<()> {
    // ç®€åŒ–å®ç° - æ ‡è®°åˆ é™¤æˆåŠŸ
    Ok(())
}

async fn insert_qdrant_point(cluster: &TestCluster, collection: &str, point: QdrantPoint) -> Result<()> {
    let doc = Document {
        id: point.id,
        content: point.payload.get("title").and_then(|v| v.as_str()).unwrap_or("").to_string(),
        title: point.payload.get("title").and_then(|v| v.as_str()).map(|s| s.to_string()),
        vector: Some(point.vector),
        metadata: convert_value_to_string_map(point.payload),
        ..Default::default()
    };
    cluster.insert_document(doc).await
}

async fn insert_qdrant_points_batch(cluster: &TestCluster, collection: &str, points: Vec<QdrantPoint>) -> Result<()> {
    for point in points {
        insert_qdrant_point(cluster, collection, point).await?;
    }
    Ok(())
}

async fn insert_qdrant_points_batch_on_node(cluster: &TestCluster, collection: &str, points: Vec<QdrantPoint>, node_id: usize) -> Result<()> {
    // åœ¨æŒ‡å®šèŠ‚ç‚¹ä¸Šæ’å…¥ç‚¹
    for point in points {
        let doc = Document {
            id: point.id,
            content: point.payload.get("title").and_then(|v| v.as_str()).unwrap_or("").to_string(),
            title: point.payload.get("title").and_then(|v| v.as_str()).map(|s| s.to_string()),
            vector: Some(point.vector),
            metadata: convert_value_to_string_map(point.payload),
            ..Default::default()
        };
        cluster.insert_document_on_node(doc, node_id).await?;
    }
    Ok(())
}

async fn retrieve_qdrant_point(cluster: &TestCluster, collection: &str, id: &str) -> Result<QdrantPoint> {
    let doc = cluster.get_document(id).await?;
    Ok(QdrantPoint {
        id: doc.id,
        vector: doc.vector.unwrap_or_default(),
        payload: doc.metadata.unwrap_or_default(),
    })
}

async fn search_qdrant_points(cluster: &TestCluster, collection: &str, vector: Vec<f32>, limit: usize, filter: Option<Value>) -> Result<Vec<QdrantPoint>> {
    let query = if let Some(title) = filter.and_then(|f| f.get("must")).and_then(|m| m.get(0)).and_then(|c| c.get("match")).and_then(|ma| ma.get("value")).and_then(|v| v.as_str()) {
        title.to_string()
    } else {
        "test".to_string() // é»˜è®¤æŸ¥è¯¢
    };
    
    let results = cluster.search_documents(&query, limit).await?;
    
    Ok(results.into_iter().map(|doc| QdrantPoint {
        id: doc.id,
        vector: doc.vector.unwrap_or_default(),
        payload: doc.metadata.unwrap_or_default(),
    }).collect())
}

async fn search_qdrant_points_on_node(cluster: &TestCluster, collection: &str, vector: Vec<f32>, limit: usize, filter: Option<Value>, node_id: usize) -> Result<Vec<QdrantPoint>> {
    // åœ¨æŒ‡å®šèŠ‚ç‚¹ä¸Šæœç´¢
    let query = "test".to_string();
    let results = cluster.search_documents_on_node(&query, limit, node_id).await?;
    
    Ok(results.into_iter().map(|doc| QdrantPoint {
        id: doc.id,
        vector: doc.vector.unwrap_or_default(),
        payload: doc.metadata.unwrap_or_default(),
    }).collect())
}

async fn delete_qdrant_point(cluster: &TestCluster, collection: &str, id: &str) -> Result<()> {
    cluster.delete_document(id).await
}

fn generate_test_vector(dimension: usize) -> Vec<f32> {
    (0..dimension).map(|i| (i as f32 * 0.01).sin()).collect()
}

fn convert_value_to_string_map(value: Value) -> std::collections::HashMap<String, String> {
    let mut map = std::collections::HashMap::new();
    if let Value::Object(obj) = value {
        for (k, v) in obj {
            let string_val = match v {
                Value::String(s) => s,
                Value::Number(n) => n.to_string(),
                Value::Bool(b) => b.to_string(),
                _ => serde_json::to_string(&v).unwrap_or_default(),
            };
            map.insert(k, string_val);
        }
    }
    map
}